{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hyo0GQ5XRFgq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tab = pd.read_csv('../../data/heston_dor.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwKSfcT5RFmW"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_-EeTiTRFrR"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDPJ3VFGfA-E"
   },
   "outputs": [],
   "source": [
    "col = [str(i) for i in range(5,5+88)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "v_iiA1ibiAYJ",
    "outputId": "657d1a4e-7177-4691-b417-33954eb52d59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016840</td>\n",
       "      <td>-0.124106</td>\n",
       "      <td>0.876229</td>\n",
       "      <td>0.164721</td>\n",
       "      <td>9.580288</td>\n",
       "      <td>0.351275</td>\n",
       "      <td>0.321272</td>\n",
       "      <td>0.294827</td>\n",
       "      <td>0.272889</td>\n",
       "      <td>0.258973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391454</td>\n",
       "      <td>0.391977</td>\n",
       "      <td>0.392578</td>\n",
       "      <td>0.393221</td>\n",
       "      <td>0.393885</td>\n",
       "      <td>0.394556</td>\n",
       "      <td>0.395226</td>\n",
       "      <td>0.395891</td>\n",
       "      <td>0.396546</td>\n",
       "      <td>0.397191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015854</td>\n",
       "      <td>-0.266165</td>\n",
       "      <td>0.140586</td>\n",
       "      <td>0.165832</td>\n",
       "      <td>7.190494</td>\n",
       "      <td>0.303108</td>\n",
       "      <td>0.235170</td>\n",
       "      <td>0.235567</td>\n",
       "      <td>0.237021</td>\n",
       "      <td>0.239069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392158</td>\n",
       "      <td>0.392608</td>\n",
       "      <td>0.393003</td>\n",
       "      <td>0.393357</td>\n",
       "      <td>0.393676</td>\n",
       "      <td>0.393969</td>\n",
       "      <td>0.394238</td>\n",
       "      <td>0.394487</td>\n",
       "      <td>0.394720</td>\n",
       "      <td>0.394938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011428</td>\n",
       "      <td>-0.337197</td>\n",
       "      <td>0.864070</td>\n",
       "      <td>0.052406</td>\n",
       "      <td>8.424803</td>\n",
       "      <td>0.334141</td>\n",
       "      <td>0.247264</td>\n",
       "      <td>0.215370</td>\n",
       "      <td>0.183602</td>\n",
       "      <td>0.152755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207557</td>\n",
       "      <td>0.209541</td>\n",
       "      <td>0.212320</td>\n",
       "      <td>0.215543</td>\n",
       "      <td>0.218976</td>\n",
       "      <td>0.222469</td>\n",
       "      <td>0.225933</td>\n",
       "      <td>0.229315</td>\n",
       "      <td>0.232585</td>\n",
       "      <td>0.235730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018240</td>\n",
       "      <td>-0.164814</td>\n",
       "      <td>0.952380</td>\n",
       "      <td>0.141195</td>\n",
       "      <td>9.059640</td>\n",
       "      <td>0.347968</td>\n",
       "      <td>0.314932</td>\n",
       "      <td>0.284821</td>\n",
       "      <td>0.258275</td>\n",
       "      <td>0.239569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359349</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.361182</td>\n",
       "      <td>0.362233</td>\n",
       "      <td>0.363318</td>\n",
       "      <td>0.364413</td>\n",
       "      <td>0.365505</td>\n",
       "      <td>0.366585</td>\n",
       "      <td>0.367648</td>\n",
       "      <td>0.368690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003158</td>\n",
       "      <td>-0.422433</td>\n",
       "      <td>0.988612</td>\n",
       "      <td>0.111454</td>\n",
       "      <td>7.498527</td>\n",
       "      <td>0.298448</td>\n",
       "      <td>0.253565</td>\n",
       "      <td>0.222731</td>\n",
       "      <td>0.193363</td>\n",
       "      <td>0.169673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.302998</td>\n",
       "      <td>0.307304</td>\n",
       "      <td>0.311453</td>\n",
       "      <td>0.315409</td>\n",
       "      <td>0.319165</td>\n",
       "      <td>0.322723</td>\n",
       "      <td>0.326092</td>\n",
       "      <td>0.329283</td>\n",
       "      <td>0.332309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.016840 -0.124106  0.876229  0.164721  9.580288  0.351275  0.321272   \n",
       "1  0.015854 -0.266165  0.140586  0.165832  7.190494  0.303108  0.235170   \n",
       "2  0.011428 -0.337197  0.864070  0.052406  8.424803  0.334141  0.247264   \n",
       "3  0.018240 -0.164814  0.952380  0.141195  9.059640  0.347968  0.314932   \n",
       "4  0.003158 -0.422433  0.988612  0.111454  7.498527  0.298448  0.253565   \n",
       "\n",
       "          7         8         9  ...        83        84        85        86  \\\n",
       "0  0.294827  0.272889  0.258973  ...  0.391454  0.391977  0.392578  0.393221   \n",
       "1  0.235567  0.237021  0.239069  ...  0.392158  0.392608  0.393003  0.393357   \n",
       "2  0.215370  0.183602  0.152755  ...  0.207557  0.209541  0.212320  0.215543   \n",
       "3  0.284821  0.258275  0.239569  ...  0.359349  0.360200  0.361182  0.362233   \n",
       "4  0.222731  0.193363  0.169673  ...  0.298614  0.302998  0.307304  0.311453   \n",
       "\n",
       "         87        88        89        90        91        92  \n",
       "0  0.393885  0.394556  0.395226  0.395891  0.396546  0.397191  \n",
       "1  0.393676  0.393969  0.394238  0.394487  0.394720  0.394938  \n",
       "2  0.218976  0.222469  0.225933  0.229315  0.232585  0.235730  \n",
       "3  0.363318  0.364413  0.365505  0.366585  0.367648  0.368690  \n",
       "4  0.315409  0.319165  0.322723  0.326092  0.329283  0.332309  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C8_WCfODiCVS",
    "outputId": "31fef9db-2459-410a-e357-63b6b6a1cc29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 93)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CCkHd3R3fdQ3"
   },
   "outputs": [],
   "source": [
    "features_dataset = tab.drop(columns=col)\n",
    "labels_dataset = tab.drop(columns=['0','1','2','3','4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Xcrr2gAoV4b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_dataset, labels_dataset, test_size=0.15, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "scale1=  StandardScaler()\n",
    "y_train_transform = scale.fit_transform(y_train)\n",
    "y_test_transform = scale.transform(y_test)\n",
    "x_train_transform = scale1.fit_transform(X_train)\n",
    "x_test_transform = scale1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "Uop2KPSrfZpt",
    "outputId": "9ba88845-7a2d-4841-a92f-cd91aea1a829"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8933</th>\n",
       "      <td>0.009083</td>\n",
       "      <td>-0.166628</td>\n",
       "      <td>0.093578</td>\n",
       "      <td>0.184929</td>\n",
       "      <td>2.174483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>0.005368</td>\n",
       "      <td>-0.658318</td>\n",
       "      <td>0.119319</td>\n",
       "      <td>0.199931</td>\n",
       "      <td>8.063958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>0.023112</td>\n",
       "      <td>-0.246583</td>\n",
       "      <td>0.777880</td>\n",
       "      <td>0.156305</td>\n",
       "      <td>9.704601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6211</th>\n",
       "      <td>0.030216</td>\n",
       "      <td>-0.101042</td>\n",
       "      <td>0.992489</td>\n",
       "      <td>0.156289</td>\n",
       "      <td>9.494351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7928</th>\n",
       "      <td>0.030184</td>\n",
       "      <td>-0.829353</td>\n",
       "      <td>0.061386</td>\n",
       "      <td>0.123217</td>\n",
       "      <td>6.891315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4\n",
       "8933  0.009083 -0.166628  0.093578  0.184929  2.174483\n",
       "4122  0.005368 -0.658318  0.119319  0.199931  8.063958\n",
       "4807  0.023112 -0.246583  0.777880  0.156305  9.704601\n",
       "6211  0.030216 -0.101042  0.992489  0.156289  9.494351\n",
       "7928  0.030184 -0.829353  0.061386  0.123217  6.891315"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "oRpKGEQDgXT4",
    "outputId": "aa969ba5-a7a2-4d27-9408-f34b1b07bc8a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8933</th>\n",
       "      <td>0.311893</td>\n",
       "      <td>0.226829</td>\n",
       "      <td>0.162880</td>\n",
       "      <td>0.161626</td>\n",
       "      <td>0.161800</td>\n",
       "      <td>0.163128</td>\n",
       "      <td>0.165218</td>\n",
       "      <td>0.167742</td>\n",
       "      <td>0.170466</td>\n",
       "      <td>0.173247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378533</td>\n",
       "      <td>0.378979</td>\n",
       "      <td>0.379389</td>\n",
       "      <td>0.379768</td>\n",
       "      <td>0.380121</td>\n",
       "      <td>0.380451</td>\n",
       "      <td>0.380762</td>\n",
       "      <td>0.381056</td>\n",
       "      <td>0.381335</td>\n",
       "      <td>0.381600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>0.311940</td>\n",
       "      <td>0.235094</td>\n",
       "      <td>0.240143</td>\n",
       "      <td>0.246018</td>\n",
       "      <td>0.251334</td>\n",
       "      <td>0.256152</td>\n",
       "      <td>0.260535</td>\n",
       "      <td>0.264542</td>\n",
       "      <td>0.268224</td>\n",
       "      <td>0.271624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429742</td>\n",
       "      <td>0.430547</td>\n",
       "      <td>0.431245</td>\n",
       "      <td>0.431861</td>\n",
       "      <td>0.432413</td>\n",
       "      <td>0.432912</td>\n",
       "      <td>0.433368</td>\n",
       "      <td>0.433787</td>\n",
       "      <td>0.434176</td>\n",
       "      <td>0.434537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>0.323462</td>\n",
       "      <td>0.298445</td>\n",
       "      <td>0.277314</td>\n",
       "      <td>0.261811</td>\n",
       "      <td>0.255693</td>\n",
       "      <td>0.261731</td>\n",
       "      <td>0.275910</td>\n",
       "      <td>0.292396</td>\n",
       "      <td>0.308458</td>\n",
       "      <td>0.323325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378391</td>\n",
       "      <td>0.379838</td>\n",
       "      <td>0.381209</td>\n",
       "      <td>0.382506</td>\n",
       "      <td>0.383734</td>\n",
       "      <td>0.384898</td>\n",
       "      <td>0.386003</td>\n",
       "      <td>0.387055</td>\n",
       "      <td>0.388059</td>\n",
       "      <td>0.389018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6211</th>\n",
       "      <td>0.377378</td>\n",
       "      <td>0.343911</td>\n",
       "      <td>0.313828</td>\n",
       "      <td>0.287870</td>\n",
       "      <td>0.269812</td>\n",
       "      <td>0.266856</td>\n",
       "      <td>0.278951</td>\n",
       "      <td>0.296877</td>\n",
       "      <td>0.315113</td>\n",
       "      <td>0.332093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382320</td>\n",
       "      <td>0.382584</td>\n",
       "      <td>0.383021</td>\n",
       "      <td>0.383564</td>\n",
       "      <td>0.384175</td>\n",
       "      <td>0.384828</td>\n",
       "      <td>0.385506</td>\n",
       "      <td>0.386197</td>\n",
       "      <td>0.386894</td>\n",
       "      <td>0.387591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7928</th>\n",
       "      <td>0.311963</td>\n",
       "      <td>0.237226</td>\n",
       "      <td>0.221845</td>\n",
       "      <td>0.227188</td>\n",
       "      <td>0.231815</td>\n",
       "      <td>0.235882</td>\n",
       "      <td>0.239503</td>\n",
       "      <td>0.242760</td>\n",
       "      <td>0.245716</td>\n",
       "      <td>0.248418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338119</td>\n",
       "      <td>0.338890</td>\n",
       "      <td>0.339557</td>\n",
       "      <td>0.340146</td>\n",
       "      <td>0.340671</td>\n",
       "      <td>0.341147</td>\n",
       "      <td>0.341580</td>\n",
       "      <td>0.341979</td>\n",
       "      <td>0.342347</td>\n",
       "      <td>0.342691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             5         6         7         8         9        10        11  \\\n",
       "8933  0.311893  0.226829  0.162880  0.161626  0.161800  0.163128  0.165218   \n",
       "4122  0.311940  0.235094  0.240143  0.246018  0.251334  0.256152  0.260535   \n",
       "4807  0.323462  0.298445  0.277314  0.261811  0.255693  0.261731  0.275910   \n",
       "6211  0.377378  0.343911  0.313828  0.287870  0.269812  0.266856  0.278951   \n",
       "7928  0.311963  0.237226  0.221845  0.227188  0.231815  0.235882  0.239503   \n",
       "\n",
       "            12        13        14  ...        83        84        85  \\\n",
       "8933  0.167742  0.170466  0.173247  ...  0.378533  0.378979  0.379389   \n",
       "4122  0.264542  0.268224  0.271624  ...  0.429742  0.430547  0.431245   \n",
       "4807  0.292396  0.308458  0.323325  ...  0.378391  0.379838  0.381209   \n",
       "6211  0.296877  0.315113  0.332093  ...  0.382320  0.382584  0.383021   \n",
       "7928  0.242760  0.245716  0.248418  ...  0.338119  0.338890  0.339557   \n",
       "\n",
       "            86        87        88        89        90        91        92  \n",
       "8933  0.379768  0.380121  0.380451  0.380762  0.381056  0.381335  0.381600  \n",
       "4122  0.431861  0.432413  0.432912  0.433368  0.433787  0.434176  0.434537  \n",
       "4807  0.382506  0.383734  0.384898  0.386003  0.387055  0.388059  0.389018  \n",
       "6211  0.383564  0.384175  0.384828  0.385506  0.386197  0.386894  0.387591  \n",
       "7928  0.340146  0.340671  0.341147  0.341580  0.341979  0.342347  0.342691  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "d-5YmyKyRF3Z",
    "outputId": "070fdf14-82f3-4a57-b983-434bc4555199"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10200, 5), (1800, 5))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train), np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cjO5fZhspF7Z"
   },
   "outputs": [],
   "source": [
    "def xtransform(X_train,X_test):\n",
    "    return [scale1.transform(X_train),scale1.transform(X_test)]\n",
    "\n",
    "    \n",
    "[x_train_transform,x_test_transform]=xtransform(X_train,X_test)\n",
    "\n",
    "def xinversetransform(x):\n",
    "    return scale.inverse_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w408NiU9pFy7"
   },
   "outputs": [],
   "source": [
    "ub=[0.04,-0.1,1.0,0.2,10.0]\n",
    "lb=[0.0001,-0.95,0.01,0.01,1]\n",
    "def myscale(x):\n",
    "    res=np.zeros(5)\n",
    "    for i in range(5):\n",
    "        res[i]=(x[i] - (ub[i] + lb[i])*0.5) * 2 / (ub[i] - lb[i])    \n",
    "    return res\n",
    "\n",
    "def myinverse(x):\n",
    "    res=np.zeros(5)\n",
    "    for i in range(5):\n",
    "        res[i]=x[i]*(ub[i] - lb[i]) *0.5 + (ub[i] + lb[i])*0.5  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HCKs1TCBq11h",
    "outputId": "a2b17278-3eb5-4362-ee3e-a4beb063aa52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10200, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_82lpi4aplXO",
    "outputId": "0b800d90-5231-4b5a-c62d-930c43ef20b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 88)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nzhQqUKwpQOQ"
   },
   "outputs": [],
   "source": [
    "#y_train_transform = np.array([myscale(y) for y in y_train])\n",
    "#y_test_transform = np.array([myscale(y) for y in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VvsbL8yHq_l8",
    "outputId": "4064956c-699d-4e17-a8b8-d07c26751a9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10200, 88)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ObaXGtV9rJNk",
    "outputId": "fad5c2a4-59c4-4b81-af42-8d577300a635"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1800, 5), (1800, 88))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_transform.shape,y_test_transform.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6NlmvKzxRdCK"
   },
   "source": [
    "## Papier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3svVI8kiRFuf"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(5,)),\n",
    "        tf.keras.layers.Dense(30,activation = 'elu'),\n",
    "        tf.keras.layers.Dense(30,activation = 'elu'),\n",
    "        tf.keras.layers.Dense(30,activation = 'elu'),\n",
    "        tf.keras.layers.Dense(88,activation = 'linear')\n",
    "    ])\n",
    "\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return tf.math.sqrt(tf.reduce_mean(tf.math.square(y_pred - y_true)))\n",
    "    \n",
    "    model.compile(loss = root_mean_squared_error, optimizer = \"adam\" ,metrics=['mae','mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exNPa7IwRFpB"
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "ZttE5FgpRhyI",
    "outputId": "c0876757-ea0d-4b08-dd89-6d2d7f7dd676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 30)                180       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 88)                2728      \n",
      "=================================================================\n",
      "Total params: 4,768\n",
      "Trainable params: 4,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 841
    },
    "colab_type": "code",
    "id": "sRWjBPytRij4",
    "outputId": "1e6bcab7-c134-4c3f-9687-4b3f679c04e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10200 samples, validate on 1800 samples\n",
      "Epoch 1/500\n",
      "10200/10200 [==============================] - 1s 70us/sample - loss: 0.3324 - mae: 0.2413 - mse: 0.1617 - val_loss: 0.1760 - val_mae: 0.1125 - val_mse: 0.0314\n",
      "Epoch 2/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.1475 - mae: 0.0900 - mse: 0.0223 - val_loss: 0.1359 - val_mae: 0.0797 - val_mse: 0.0189\n",
      "Epoch 3/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.1182 - mae: 0.0695 - mse: 0.0144 - val_loss: 0.1086 - val_mae: 0.0667 - val_mse: 0.0120\n",
      "Epoch 4/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0973 - mae: 0.0583 - mse: 0.0098 - val_loss: 0.0921 - val_mae: 0.0558 - val_mse: 0.0087\n",
      "Epoch 5/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0833 - mae: 0.0494 - mse: 0.0072 - val_loss: 0.0784 - val_mae: 0.0463 - val_mse: 0.0063\n",
      "Epoch 6/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0746 - mae: 0.0434 - mse: 0.0058 - val_loss: 0.0702 - val_mae: 0.0411 - val_mse: 0.0051\n",
      "Epoch 7/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0670 - mae: 0.0380 - mse: 0.0046 - val_loss: 0.0645 - val_mae: 0.0363 - val_mse: 0.0043\n",
      "Epoch 8/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0618 - mae: 0.0349 - mse: 0.0039 - val_loss: 0.0584 - val_mae: 0.0319 - val_mse: 0.0035\n",
      "Epoch 9/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0571 - mae: 0.0317 - mse: 0.0034 - val_loss: 0.0545 - val_mae: 0.0298 - val_mse: 0.0031\n",
      "Epoch 10/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0540 - mae: 0.0298 - mse: 0.0030 - val_loss: 0.0510 - val_mae: 0.0272 - val_mse: 0.0027\n",
      "Epoch 11/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0515 - mae: 0.0286 - mse: 0.0027 - val_loss: 0.0490 - val_mae: 0.0263 - val_mse: 0.0025\n",
      "Epoch 12/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0492 - mae: 0.0272 - mse: 0.0025 - val_loss: 0.0482 - val_mae: 0.0274 - val_mse: 0.0024\n",
      "Epoch 13/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0478 - mae: 0.0261 - mse: 0.0024 - val_loss: 0.0465 - val_mae: 0.0256 - val_mse: 0.0022\n",
      "Epoch 14/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0460 - mae: 0.0248 - mse: 0.0022 - val_loss: 0.0476 - val_mae: 0.0268 - val_mse: 0.0023\n",
      "Epoch 15/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0448 - mae: 0.0241 - mse: 0.0021 - val_loss: 0.0428 - val_mae: 0.0226 - val_mse: 0.0019\n",
      "Epoch 16/500\n",
      "10200/10200 [==============================] - 0s 42us/sample - loss: 0.0438 - mae: 0.0234 - mse: 0.0020 - val_loss: 0.0445 - val_mae: 0.0263 - val_mse: 0.0020\n",
      "Epoch 17/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0434 - mae: 0.0232 - mse: 0.0019 - val_loss: 0.0440 - val_mae: 0.0226 - val_mse: 0.0020\n",
      "Epoch 18/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0421 - mae: 0.0221 - mse: 0.0018 - val_loss: 0.0406 - val_mae: 0.0209 - val_mse: 0.0017\n",
      "Epoch 19/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0416 - mae: 0.0217 - mse: 0.0018 - val_loss: 0.0417 - val_mae: 0.0223 - val_mse: 0.0018\n",
      "Epoch 20/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0405 - mae: 0.0205 - mse: 0.0017 - val_loss: 0.0411 - val_mae: 0.0215 - val_mse: 0.0017\n",
      "Epoch 21/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0412 - mae: 0.0218 - mse: 0.0017 - val_loss: 0.0398 - val_mae: 0.0204 - val_mse: 0.0016\n",
      "Epoch 22/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0402 - mae: 0.0210 - mse: 0.0017 - val_loss: 0.0405 - val_mae: 0.0223 - val_mse: 0.0017\n",
      "Epoch 23/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0401 - mae: 0.0210 - mse: 0.0017 - val_loss: 0.0385 - val_mae: 0.0194 - val_mse: 0.0015\n",
      "Epoch 24/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0391 - mae: 0.0197 - mse: 0.0016 - val_loss: 0.0391 - val_mae: 0.0205 - val_mse: 0.0016\n",
      "Epoch 25/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0387 - mae: 0.0194 - mse: 0.0015 - val_loss: 0.0426 - val_mae: 0.0246 - val_mse: 0.0019\n",
      "Epoch 26/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0384 - mae: 0.0194 - mse: 0.0015 - val_loss: 0.0378 - val_mae: 0.0186 - val_mse: 0.0015\n",
      "Epoch 27/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0382 - mae: 0.0192 - mse: 0.0015 - val_loss: 0.0376 - val_mae: 0.0182 - val_mse: 0.0014\n",
      "Epoch 28/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0382 - mae: 0.0194 - mse: 0.0015 - val_loss: 0.0361 - val_mae: 0.0180 - val_mse: 0.0013\n",
      "Epoch 29/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0374 - mae: 0.0188 - mse: 0.0014 - val_loss: 0.0379 - val_mae: 0.0194 - val_mse: 0.0015\n",
      "Epoch 30/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0373 - mae: 0.0184 - mse: 0.0014 - val_loss: 0.0370 - val_mae: 0.0182 - val_mse: 0.0014\n",
      "Epoch 31/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0369 - mae: 0.0180 - mse: 0.0014 - val_loss: 0.0359 - val_mae: 0.0179 - val_mse: 0.0013\n",
      "Epoch 32/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0366 - mae: 0.0180 - mse: 0.0014 - val_loss: 0.0371 - val_mae: 0.0192 - val_mse: 0.0014\n",
      "Epoch 33/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0367 - mae: 0.0182 - mse: 0.0014 - val_loss: 0.0363 - val_mae: 0.0184 - val_mse: 0.0014\n",
      "Epoch 34/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0365 - mae: 0.0181 - mse: 0.0014 - val_loss: 0.0378 - val_mae: 0.0201 - val_mse: 0.0015\n",
      "Epoch 35/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0366 - mae: 0.0183 - mse: 0.0014 - val_loss: 0.0369 - val_mae: 0.0189 - val_mse: 0.0014\n",
      "Epoch 36/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0358 - mae: 0.0170 - mse: 0.0013 - val_loss: 0.0359 - val_mae: 0.0177 - val_mse: 0.0013\n",
      "Epoch 37/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0360 - mae: 0.0177 - mse: 0.0013 - val_loss: 0.0347 - val_mae: 0.0162 - val_mse: 0.0012\n",
      "Epoch 38/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0356 - mae: 0.0173 - mse: 0.0013 - val_loss: 0.0335 - val_mae: 0.0155 - val_mse: 0.0012\n",
      "Epoch 39/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0359 - mae: 0.0177 - mse: 0.0013 - val_loss: 0.0343 - val_mae: 0.0173 - val_mse: 0.0012\n",
      "Epoch 40/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0353 - mae: 0.0171 - mse: 0.0013 - val_loss: 0.0383 - val_mae: 0.0212 - val_mse: 0.0015\n",
      "Epoch 41/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0354 - mae: 0.0171 - mse: 0.0013 - val_loss: 0.0355 - val_mae: 0.0193 - val_mse: 0.0013\n",
      "Epoch 42/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0350 - mae: 0.0168 - mse: 0.0013 - val_loss: 0.0367 - val_mae: 0.0200 - val_mse: 0.0014\n",
      "Epoch 43/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0349 - mae: 0.0168 - mse: 0.0013 - val_loss: 0.0365 - val_mae: 0.0200 - val_mse: 0.0014\n",
      "Epoch 44/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0351 - mae: 0.0172 - mse: 0.0013 - val_loss: 0.0337 - val_mae: 0.0154 - val_mse: 0.0012\n",
      "Epoch 45/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0342 - mae: 0.0159 - mse: 0.0012 - val_loss: 0.0355 - val_mae: 0.0185 - val_mse: 0.0013\n",
      "Epoch 46/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0350 - mae: 0.0173 - mse: 0.0013 - val_loss: 0.0372 - val_mae: 0.0221 - val_mse: 0.0014\n",
      "Epoch 47/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0346 - mae: 0.0167 - mse: 0.0012 - val_loss: 0.0331 - val_mae: 0.0147 - val_mse: 0.0011\n",
      "Epoch 48/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0343 - mae: 0.0161 - mse: 0.0012 - val_loss: 0.0331 - val_mae: 0.0159 - val_mse: 0.0011\n",
      "Epoch 49/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0341 - mae: 0.0163 - mse: 0.0012 - val_loss: 0.0348 - val_mae: 0.0176 - val_mse: 0.0012\n",
      "Epoch 50/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0339 - mae: 0.0160 - mse: 0.0012 - val_loss: 0.0350 - val_mae: 0.0164 - val_mse: 0.0013\n",
      "Epoch 51/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0339 - mae: 0.0158 - mse: 0.0012 - val_loss: 0.0334 - val_mae: 0.0168 - val_mse: 0.0011\n",
      "Epoch 52/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0341 - mae: 0.0165 - mse: 0.0012 - val_loss: 0.0334 - val_mae: 0.0164 - val_mse: 0.0011\n",
      "Epoch 53/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0336 - mae: 0.0158 - mse: 0.0012 - val_loss: 0.0335 - val_mae: 0.0162 - val_mse: 0.0011\n",
      "Epoch 54/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0336 - mae: 0.0159 - mse: 0.0012 - val_loss: 0.0329 - val_mae: 0.0153 - val_mse: 0.0011\n",
      "Epoch 55/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0335 - mae: 0.0156 - mse: 0.0012 - val_loss: 0.0331 - val_mae: 0.0160 - val_mse: 0.0011\n",
      "Epoch 56/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0332 - mae: 0.0154 - mse: 0.0011 - val_loss: 0.0349 - val_mae: 0.0166 - val_mse: 0.0013\n",
      "Epoch 57/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0335 - mae: 0.0159 - mse: 0.0012 - val_loss: 0.0325 - val_mae: 0.0145 - val_mse: 0.0011\n",
      "Epoch 58/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0334 - mae: 0.0158 - mse: 0.0012 - val_loss: 0.0326 - val_mae: 0.0148 - val_mse: 0.0011\n",
      "Epoch 59/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0332 - mae: 0.0156 - mse: 0.0011 - val_loss: 0.0348 - val_mae: 0.0191 - val_mse: 0.0012\n",
      "Epoch 60/500\n",
      "10200/10200 [==============================] - 0s 42us/sample - loss: 0.0325 - mae: 0.0149 - mse: 0.0011 - val_loss: 0.0322 - val_mae: 0.0139 - val_mse: 0.0011\n",
      "Epoch 61/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0325 - mae: 0.0146 - mse: 0.0011 - val_loss: 0.0329 - val_mae: 0.0137 - val_mse: 0.0011\n",
      "Epoch 62/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0331 - mae: 0.0155 - mse: 0.0011 - val_loss: 0.0345 - val_mae: 0.0164 - val_mse: 0.0012\n",
      "Epoch 63/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0331 - mae: 0.0157 - mse: 0.0011 - val_loss: 0.0326 - val_mae: 0.0152 - val_mse: 0.0011\n",
      "Epoch 64/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0326 - mae: 0.0150 - mse: 0.0011 - val_loss: 0.0318 - val_mae: 0.0148 - val_mse: 0.0010\n",
      "Epoch 65/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0326 - mae: 0.0152 - mse: 0.0011 - val_loss: 0.0337 - val_mae: 0.0184 - val_mse: 0.0012\n",
      "Epoch 66/500\n",
      "10200/10200 [==============================] - 0s 42us/sample - loss: 0.0324 - mae: 0.0150 - mse: 0.0011 - val_loss: 0.0314 - val_mae: 0.0142 - val_mse: 0.0010\n",
      "Epoch 67/500\n",
      "10200/10200 [==============================] - 1s 64us/sample - loss: 0.0323 - mae: 0.0145 - mse: 0.0011 - val_loss: 0.0328 - val_mae: 0.0173 - val_mse: 0.0011\n",
      "Epoch 68/500\n",
      "10200/10200 [==============================] - 0s 43us/sample - loss: 0.0323 - mae: 0.0147 - mse: 0.0011 - val_loss: 0.0314 - val_mae: 0.0137 - val_mse: 0.0010\n",
      "Epoch 69/500\n",
      "10200/10200 [==============================] - 0s 46us/sample - loss: 0.0325 - mae: 0.0151 - mse: 0.0011 - val_loss: 0.0312 - val_mae: 0.0137 - val_mse: 0.0010\n",
      "Epoch 70/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0323 - mae: 0.0149 - mse: 0.0011 - val_loss: 0.0343 - val_mae: 0.0201 - val_mse: 0.0012\n",
      "Epoch 71/500\n",
      "10200/10200 [==============================] - 0s 46us/sample - loss: 0.0321 - mae: 0.0148 - mse: 0.0011 - val_loss: 0.0318 - val_mae: 0.0153 - val_mse: 0.0010\n",
      "Epoch 72/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0319 - mae: 0.0144 - mse: 0.0011 - val_loss: 0.0304 - val_mae: 0.0128 - val_mse: 9.5171e-04\n",
      "Epoch 73/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0318 - mae: 0.0145 - mse: 0.0011 - val_loss: 0.0304 - val_mae: 0.0124 - val_mse: 9.5295e-04\n",
      "Epoch 74/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0320 - mae: 0.0149 - mse: 0.0011 - val_loss: 0.0320 - val_mae: 0.0135 - val_mse: 0.0011\n",
      "Epoch 75/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0320 - mae: 0.0147 - mse: 0.0011 - val_loss: 0.0323 - val_mae: 0.0164 - val_mse: 0.0011\n",
      "Epoch 76/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0319 - mae: 0.0147 - mse: 0.0011 - val_loss: 0.0307 - val_mae: 0.0141 - val_mse: 9.7185e-04\n",
      "Epoch 77/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0317 - mae: 0.0142 - mse: 0.0010 - val_loss: 0.0324 - val_mae: 0.0151 - val_mse: 0.0011\n",
      "Epoch 78/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0323 - mae: 0.0156 - mse: 0.0011 - val_loss: 0.0304 - val_mae: 0.0129 - val_mse: 9.5848e-04\n",
      "Epoch 79/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0313 - mae: 0.0139 - mse: 0.0010 - val_loss: 0.0348 - val_mae: 0.0192 - val_mse: 0.0012\n",
      "Epoch 80/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0313 - mae: 0.0140 - mse: 0.0010 - val_loss: 0.0306 - val_mae: 0.0137 - val_mse: 9.6249e-04\n",
      "Epoch 81/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0314 - mae: 0.0145 - mse: 0.0010 - val_loss: 0.0317 - val_mae: 0.0169 - val_mse: 0.0010\n",
      "Epoch 82/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0311 - mae: 0.0137 - mse: 0.0010 - val_loss: 0.0302 - val_mae: 0.0134 - val_mse: 9.4768e-04\n",
      "Epoch 83/500\n",
      "10200/10200 [==============================] - 0s 42us/sample - loss: 0.0316 - mae: 0.0146 - mse: 0.0010 - val_loss: 0.0314 - val_mae: 0.0156 - val_mse: 0.0010\n",
      "Epoch 84/500\n",
      "10200/10200 [==============================] - 0s 43us/sample - loss: 0.0315 - mae: 0.0147 - mse: 0.0010 - val_loss: 0.0296 - val_mae: 0.0124 - val_mse: 9.0684e-04\n",
      "Epoch 85/500\n",
      "10200/10200 [==============================] - 0s 49us/sample - loss: 0.0308 - mae: 0.0136 - mse: 9.8367e-04 - val_loss: 0.0299 - val_mae: 0.0128 - val_mse: 9.2650e-04\n",
      "Epoch 86/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0312 - mae: 0.0142 - mse: 0.0010 - val_loss: 0.0304 - val_mae: 0.0136 - val_mse: 9.5753e-04\n",
      "Epoch 87/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0312 - mae: 0.0141 - mse: 0.0010 - val_loss: 0.0308 - val_mae: 0.0136 - val_mse: 9.8117e-04\n",
      "Epoch 88/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0316 - mae: 0.0147 - mse: 0.0010 - val_loss: 0.0319 - val_mae: 0.0147 - val_mse: 0.0011\n",
      "Epoch 89/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0311 - mae: 0.0141 - mse: 0.0010 - val_loss: 0.0324 - val_mae: 0.0162 - val_mse: 0.0011\n",
      "Epoch 90/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0307 - mae: 0.0135 - mse: 9.7344e-04 - val_loss: 0.0294 - val_mae: 0.0119 - val_mse: 8.9188e-04\n",
      "Epoch 91/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0309 - mae: 0.0137 - mse: 9.8914e-04 - val_loss: 0.0319 - val_mae: 0.0153 - val_mse: 0.0010\n",
      "Epoch 92/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0308 - mae: 0.0137 - mse: 9.7916e-04 - val_loss: 0.0299 - val_mae: 0.0126 - val_mse: 9.2018e-04\n",
      "Epoch 93/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0308 - mae: 0.0136 - mse: 9.8267e-04 - val_loss: 0.0298 - val_mae: 0.0134 - val_mse: 9.1928e-04\n",
      "Epoch 94/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0309 - mae: 0.0139 - mse: 9.8612e-04 - val_loss: 0.0303 - val_mae: 0.0132 - val_mse: 9.5093e-04\n",
      "Epoch 95/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0307 - mae: 0.0135 - mse: 9.7434e-04 - val_loss: 0.0301 - val_mae: 0.0131 - val_mse: 9.3308e-04\n",
      "Epoch 96/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0305 - mae: 0.0136 - mse: 9.6780e-04 - val_loss: 0.0296 - val_mae: 0.0138 - val_mse: 9.0960e-04\n",
      "Epoch 97/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0307 - mae: 0.0138 - mse: 9.7136e-04 - val_loss: 0.0312 - val_mae: 0.0137 - val_mse: 9.9652e-04\n",
      "Epoch 98/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0304 - mae: 0.0136 - mse: 9.6172e-04 - val_loss: 0.0294 - val_mae: 0.0133 - val_mse: 8.9442e-04\n",
      "Epoch 99/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0304 - mae: 0.0136 - mse: 9.5316e-04 - val_loss: 0.0307 - val_mae: 0.0134 - val_mse: 9.6323e-04\n",
      "Epoch 100/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0307 - mae: 0.0138 - mse: 9.7647e-04 - val_loss: 0.0296 - val_mae: 0.0117 - val_mse: 9.0951e-04\n",
      "Epoch 101/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0303 - mae: 0.0133 - mse: 9.5363e-04 - val_loss: 0.0318 - val_mae: 0.0140 - val_mse: 0.0010\n",
      "Epoch 102/500\n",
      "10200/10200 [==============================] - 0s 42us/sample - loss: 0.0307 - mae: 0.0141 - mse: 9.7639e-04 - val_loss: 0.0292 - val_mae: 0.0121 - val_mse: 8.8212e-04\n",
      "Epoch 103/500\n",
      "10200/10200 [==============================] - 1s 51us/sample - loss: 0.0305 - mae: 0.0135 - mse: 9.5693e-04 - val_loss: 0.0290 - val_mae: 0.0113 - val_mse: 8.6687e-04\n",
      "Epoch 104/500\n",
      "10200/10200 [==============================] - 1s 55us/sample - loss: 0.0304 - mae: 0.0133 - mse: 9.5435e-04 - val_loss: 0.0290 - val_mae: 0.0120 - val_mse: 8.7395e-04\n",
      "Epoch 105/500\n",
      "10200/10200 [==============================] - 0s 43us/sample - loss: 0.0306 - mae: 0.0138 - mse: 9.6870e-04 - val_loss: 0.0315 - val_mae: 0.0161 - val_mse: 0.0010\n",
      "Epoch 106/500\n",
      "10200/10200 [==============================] - 0s 42us/sample - loss: 0.0299 - mae: 0.0128 - mse: 9.2666e-04 - val_loss: 0.0303 - val_mae: 0.0134 - val_mse: 9.4343e-04\n",
      "Epoch 107/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0301 - mae: 0.0132 - mse: 9.3501e-04 - val_loss: 0.0301 - val_mae: 0.0137 - val_mse: 9.3492e-04\n",
      "Epoch 108/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0305 - mae: 0.0139 - mse: 9.6102e-04 - val_loss: 0.0302 - val_mae: 0.0138 - val_mse: 9.3957e-04\n",
      "Epoch 109/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0300 - mae: 0.0131 - mse: 9.3173e-04 - val_loss: 0.0303 - val_mae: 0.0136 - val_mse: 9.4463e-04\n",
      "Epoch 110/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0302 - mae: 0.0136 - mse: 9.4321e-04 - val_loss: 0.0304 - val_mae: 0.0122 - val_mse: 9.6415e-04\n",
      "Epoch 111/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0302 - mae: 0.0135 - mse: 9.4353e-04 - val_loss: 0.0294 - val_mae: 0.0129 - val_mse: 8.9009e-04\n",
      "Epoch 112/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0300 - mae: 0.0132 - mse: 9.3284e-04 - val_loss: 0.0289 - val_mae: 0.0120 - val_mse: 8.6496e-04\n",
      "Epoch 113/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0303 - mae: 0.0138 - mse: 9.4748e-04 - val_loss: 0.0295 - val_mae: 0.0123 - val_mse: 8.9905e-04\n",
      "Epoch 114/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0302 - mae: 0.0136 - mse: 9.4435e-04 - val_loss: 0.0332 - val_mae: 0.0179 - val_mse: 0.0011\n",
      "Epoch 115/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0299 - mae: 0.0132 - mse: 9.2407e-04 - val_loss: 0.0290 - val_mae: 0.0120 - val_mse: 8.7284e-04\n",
      "Epoch 116/500\n",
      "10200/10200 [==============================] - 0s 32us/sample - loss: 0.0303 - mae: 0.0138 - mse: 9.4961e-04 - val_loss: 0.0296 - val_mae: 0.0129 - val_mse: 8.9996e-04\n",
      "Epoch 117/500\n",
      "10200/10200 [==============================] - 0s 32us/sample - loss: 0.0300 - mae: 0.0135 - mse: 9.3224e-04 - val_loss: 0.0315 - val_mae: 0.0167 - val_mse: 0.0010\n",
      "Epoch 118/500\n",
      "10200/10200 [==============================] - 0s 34us/sample - loss: 0.0297 - mae: 0.0129 - mse: 9.0978e-04 - val_loss: 0.0314 - val_mae: 0.0170 - val_mse: 0.0010\n",
      "Epoch 119/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0295 - mae: 0.0124 - mse: 9.0198e-04 - val_loss: 0.0301 - val_mae: 0.0125 - val_mse: 9.3908e-04\n",
      "Epoch 120/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0300 - mae: 0.0133 - mse: 9.3275e-04 - val_loss: 0.0304 - val_mae: 0.0132 - val_mse: 9.4693e-04\n",
      "Epoch 121/500\n",
      "10200/10200 [==============================] - 0s 34us/sample - loss: 0.0294 - mae: 0.0126 - mse: 9.0017e-04 - val_loss: 0.0307 - val_mae: 0.0121 - val_mse: 9.7321e-04\n",
      "Epoch 122/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0297 - mae: 0.0130 - mse: 9.1407e-04 - val_loss: 0.0287 - val_mae: 0.0117 - val_mse: 8.4785e-04\n",
      "Epoch 123/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0301 - mae: 0.0134 - mse: 9.3238e-04 - val_loss: 0.0301 - val_mae: 0.0140 - val_mse: 9.2877e-04\n",
      "Epoch 124/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0296 - mae: 0.0131 - mse: 9.0698e-04 - val_loss: 0.0295 - val_mae: 0.0125 - val_mse: 8.9964e-04\n",
      "Epoch 125/500\n",
      "10200/10200 [==============================] - 0s 34us/sample - loss: 0.0298 - mae: 0.0132 - mse: 9.1868e-04 - val_loss: 0.0295 - val_mae: 0.0115 - val_mse: 9.0299e-04\n",
      "Epoch 126/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0299 - mae: 0.0132 - mse: 9.2123e-04 - val_loss: 0.0300 - val_mae: 0.0137 - val_mse: 9.2711e-04\n",
      "Epoch 127/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0297 - mae: 0.0132 - mse: 9.1397e-04 - val_loss: 0.0298 - val_mae: 0.0131 - val_mse: 9.2024e-04\n",
      "Epoch 128/500\n",
      "10200/10200 [==============================] - 0s 33us/sample - loss: 0.0292 - mae: 0.0126 - mse: 8.8669e-04 - val_loss: 0.0294 - val_mae: 0.0134 - val_mse: 8.8846e-04\n",
      "Epoch 129/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0296 - mae: 0.0127 - mse: 9.0309e-04 - val_loss: 0.0295 - val_mae: 0.0132 - val_mse: 8.9888e-04\n",
      "Epoch 130/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0296 - mae: 0.0129 - mse: 9.0325e-04 - val_loss: 0.0298 - val_mae: 0.0134 - val_mse: 9.1495e-04\n",
      "Epoch 131/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0293 - mae: 0.0127 - mse: 8.8849e-04 - val_loss: 0.0330 - val_mae: 0.0184 - val_mse: 0.0011\n",
      "Epoch 132/500\n",
      "10200/10200 [==============================] - 0s 43us/sample - loss: 0.0295 - mae: 0.0132 - mse: 9.0502e-04 - val_loss: 0.0308 - val_mae: 0.0153 - val_mse: 9.7851e-04\n",
      "Epoch 133/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0293 - mae: 0.0127 - mse: 8.8709e-04 - val_loss: 0.0282 - val_mae: 0.0111 - val_mse: 8.2149e-04\n",
      "Epoch 134/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0296 - mae: 0.0134 - mse: 9.1137e-04 - val_loss: 0.0300 - val_mae: 0.0143 - val_mse: 9.2426e-04\n",
      "Epoch 135/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0295 - mae: 0.0132 - mse: 9.0345e-04 - val_loss: 0.0283 - val_mae: 0.0117 - val_mse: 8.3091e-04\n",
      "Epoch 136/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0294 - mae: 0.0131 - mse: 8.9512e-04 - val_loss: 0.0283 - val_mae: 0.0111 - val_mse: 8.3179e-04\n",
      "Epoch 137/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0290 - mae: 0.0122 - mse: 8.6923e-04 - val_loss: 0.0286 - val_mae: 0.0114 - val_mse: 8.4793e-04\n",
      "Epoch 138/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0291 - mae: 0.0129 - mse: 8.7912e-04 - val_loss: 0.0315 - val_mae: 0.0173 - val_mse: 0.0010\n",
      "Epoch 139/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0294 - mae: 0.0131 - mse: 8.9587e-04 - val_loss: 0.0294 - val_mae: 0.0135 - val_mse: 8.8899e-04\n",
      "Epoch 140/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0293 - mae: 0.0129 - mse: 8.8750e-04 - val_loss: 0.0289 - val_mae: 0.0120 - val_mse: 8.6519e-04\n",
      "Epoch 141/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0291 - mae: 0.0124 - mse: 8.7983e-04 - val_loss: 0.0280 - val_mae: 0.0111 - val_mse: 8.1594e-04\n",
      "Epoch 142/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0292 - mae: 0.0129 - mse: 8.8213e-04 - val_loss: 0.0287 - val_mae: 0.0122 - val_mse: 8.4922e-04\n",
      "Epoch 143/500\n",
      "10200/10200 [==============================] - 0s 46us/sample - loss: 0.0293 - mae: 0.0129 - mse: 8.8847e-04 - val_loss: 0.0286 - val_mae: 0.0119 - val_mse: 8.4525e-04\n",
      "Epoch 144/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0290 - mae: 0.0124 - mse: 8.7401e-04 - val_loss: 0.0293 - val_mae: 0.0128 - val_mse: 8.9349e-04\n",
      "Epoch 145/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0296 - mae: 0.0136 - mse: 9.0642e-04 - val_loss: 0.0292 - val_mae: 0.0127 - val_mse: 8.7773e-04\n",
      "Epoch 146/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0288 - mae: 0.0122 - mse: 8.6438e-04 - val_loss: 0.0291 - val_mae: 0.0133 - val_mse: 8.7398e-04\n",
      "Epoch 147/500\n",
      "10200/10200 [==============================] - 0s 46us/sample - loss: 0.0296 - mae: 0.0131 - mse: 9.0779e-04 - val_loss: 0.0293 - val_mae: 0.0132 - val_mse: 8.8671e-04\n",
      "Epoch 148/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0291 - mae: 0.0127 - mse: 8.7391e-04 - val_loss: 0.0309 - val_mae: 0.0161 - val_mse: 9.8084e-04\n",
      "Epoch 149/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0289 - mae: 0.0125 - mse: 8.6720e-04 - val_loss: 0.0286 - val_mae: 0.0126 - val_mse: 8.4670e-04\n",
      "Epoch 150/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0287 - mae: 0.0122 - mse: 8.5491e-04 - val_loss: 0.0287 - val_mae: 0.0128 - val_mse: 8.5284e-04\n",
      "Epoch 151/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0292 - mae: 0.0130 - mse: 8.8437e-04 - val_loss: 0.0289 - val_mae: 0.0114 - val_mse: 8.6787e-04\n",
      "Epoch 152/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0287 - mae: 0.0122 - mse: 8.5484e-04 - val_loss: 0.0289 - val_mae: 0.0119 - val_mse: 8.5662e-04\n",
      "Epoch 153/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0288 - mae: 0.0124 - mse: 8.6127e-04 - val_loss: 0.0285 - val_mae: 0.0126 - val_mse: 8.3711e-04\n",
      "Epoch 154/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0291 - mae: 0.0131 - mse: 8.7898e-04 - val_loss: 0.0284 - val_mae: 0.0112 - val_mse: 8.3878e-04\n",
      "Epoch 155/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0289 - mae: 0.0128 - mse: 8.6174e-04 - val_loss: 0.0283 - val_mae: 0.0126 - val_mse: 8.2458e-04\n",
      "Epoch 156/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0287 - mae: 0.0126 - mse: 8.5473e-04 - val_loss: 0.0294 - val_mae: 0.0126 - val_mse: 8.8990e-04\n",
      "Epoch 157/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0283 - mae: 0.0118 - mse: 8.3402e-04 - val_loss: 0.0300 - val_mae: 0.0145 - val_mse: 9.2764e-04\n",
      "Epoch 158/500\n",
      "10200/10200 [==============================] - 0s 44us/sample - loss: 0.0284 - mae: 0.0121 - mse: 8.4025e-04 - val_loss: 0.0286 - val_mae: 0.0127 - val_mse: 8.4097e-04\n",
      "Epoch 159/500\n",
      "10200/10200 [==============================] - 0s 44us/sample - loss: 0.0283 - mae: 0.0118 - mse: 8.3427e-04 - val_loss: 0.0282 - val_mae: 0.0112 - val_mse: 8.3103e-04\n",
      "Epoch 160/500\n",
      "10200/10200 [==============================] - 1s 50us/sample - loss: 0.0285 - mae: 0.0122 - mse: 8.3872e-04 - val_loss: 0.0271 - val_mae: 0.0101 - val_mse: 7.6664e-04\n",
      "Epoch 161/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0289 - mae: 0.0127 - mse: 8.6826e-04 - val_loss: 0.0285 - val_mae: 0.0119 - val_mse: 8.4416e-04\n",
      "Epoch 162/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0286 - mae: 0.0123 - mse: 8.4657e-04 - val_loss: 0.0281 - val_mae: 0.0111 - val_mse: 8.1643e-04\n",
      "Epoch 163/500\n",
      "10200/10200 [==============================] - 0s 42us/sample - loss: 0.0284 - mae: 0.0120 - mse: 8.3504e-04 - val_loss: 0.0289 - val_mae: 0.0128 - val_mse: 8.5710e-04\n",
      "Epoch 164/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0289 - mae: 0.0129 - mse: 8.6238e-04 - val_loss: 0.0281 - val_mae: 0.0128 - val_mse: 8.1470e-04\n",
      "Epoch 165/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0281 - mae: 0.0118 - mse: 8.2276e-04 - val_loss: 0.0285 - val_mae: 0.0125 - val_mse: 8.3651e-04\n",
      "Epoch 166/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0283 - mae: 0.0122 - mse: 8.3220e-04 - val_loss: 0.0296 - val_mae: 0.0137 - val_mse: 8.9781e-04\n",
      "Epoch 167/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0283 - mae: 0.0120 - mse: 8.2938e-04 - val_loss: 0.0289 - val_mae: 0.0126 - val_mse: 8.5519e-04\n",
      "Epoch 168/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0286 - mae: 0.0125 - mse: 8.4743e-04 - val_loss: 0.0276 - val_mae: 0.0114 - val_mse: 7.8547e-04\n",
      "Epoch 169/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0281 - mae: 0.0116 - mse: 8.2096e-04 - val_loss: 0.0285 - val_mae: 0.0117 - val_mse: 8.3588e-04\n",
      "Epoch 170/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0283 - mae: 0.0119 - mse: 8.2931e-04 - val_loss: 0.0286 - val_mae: 0.0118 - val_mse: 8.4284e-04\n",
      "Epoch 171/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0284 - mae: 0.0124 - mse: 8.3685e-04 - val_loss: 0.0280 - val_mae: 0.0117 - val_mse: 8.1476e-04\n",
      "Epoch 172/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0282 - mae: 0.0120 - mse: 8.2171e-04 - val_loss: 0.0290 - val_mae: 0.0138 - val_mse: 8.6351e-04\n",
      "Epoch 173/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0284 - mae: 0.0126 - mse: 8.3933e-04 - val_loss: 0.0300 - val_mae: 0.0148 - val_mse: 9.2135e-04\n",
      "Epoch 174/500\n",
      "10200/10200 [==============================] - 0s 45us/sample - loss: 0.0284 - mae: 0.0124 - mse: 8.3900e-04 - val_loss: 0.0289 - val_mae: 0.0129 - val_mse: 8.7386e-04\n",
      "Epoch 175/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0282 - mae: 0.0119 - mse: 8.2592e-04 - val_loss: 0.0282 - val_mae: 0.0126 - val_mse: 8.2417e-04\n",
      "Epoch 176/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0282 - mae: 0.0119 - mse: 8.2411e-04 - val_loss: 0.0296 - val_mae: 0.0144 - val_mse: 8.9646e-04\n",
      "Epoch 177/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0289 - mae: 0.0130 - mse: 8.6807e-04 - val_loss: 0.0281 - val_mae: 0.0109 - val_mse: 8.1766e-04\n",
      "Epoch 178/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0280 - mae: 0.0115 - mse: 8.0704e-04 - val_loss: 0.0289 - val_mae: 0.0105 - val_mse: 8.6218e-04\n",
      "Epoch 179/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0281 - mae: 0.0118 - mse: 8.1893e-04 - val_loss: 0.0270 - val_mae: 0.0105 - val_mse: 7.5418e-04\n",
      "Epoch 180/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0282 - mae: 0.0122 - mse: 8.2459e-04 - val_loss: 0.0288 - val_mae: 0.0124 - val_mse: 8.5649e-04\n",
      "Epoch 181/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0285 - mae: 0.0124 - mse: 8.4356e-04 - val_loss: 0.0281 - val_mae: 0.0131 - val_mse: 8.1486e-04\n",
      "Epoch 182/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0286 - mae: 0.0128 - mse: 8.4669e-04 - val_loss: 0.0286 - val_mae: 0.0138 - val_mse: 8.4176e-04\n",
      "Epoch 183/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0285 - mae: 0.0128 - mse: 8.4429e-04 - val_loss: 0.0264 - val_mae: 0.0100 - val_mse: 7.2424e-04\n",
      "Epoch 184/500\n",
      "10200/10200 [==============================] - 0s 42us/sample - loss: 0.0276 - mae: 0.0114 - mse: 7.8721e-04 - val_loss: 0.0275 - val_mae: 0.0111 - val_mse: 7.7717e-04\n",
      "Epoch 185/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0282 - mae: 0.0121 - mse: 8.2544e-04 - val_loss: 0.0276 - val_mae: 0.0119 - val_mse: 7.8718e-04\n",
      "Epoch 186/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0278 - mae: 0.0117 - mse: 8.0380e-04 - val_loss: 0.0292 - val_mae: 0.0140 - val_mse: 8.7846e-04\n",
      "Epoch 187/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0281 - mae: 0.0122 - mse: 8.2010e-04 - val_loss: 0.0281 - val_mae: 0.0129 - val_mse: 8.1399e-04\n",
      "Epoch 188/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0279 - mae: 0.0119 - mse: 8.1185e-04 - val_loss: 0.0277 - val_mae: 0.0105 - val_mse: 7.8579e-04\n",
      "Epoch 189/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0280 - mae: 0.0121 - mse: 8.1133e-04 - val_loss: 0.0298 - val_mae: 0.0166 - val_mse: 9.1306e-04\n",
      "Epoch 190/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0281 - mae: 0.0122 - mse: 8.1736e-04 - val_loss: 0.0274 - val_mae: 0.0115 - val_mse: 7.7256e-04\n",
      "Epoch 191/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0280 - mae: 0.0124 - mse: 8.1564e-04 - val_loss: 0.0267 - val_mae: 0.0108 - val_mse: 7.3756e-04\n",
      "Epoch 192/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0281 - mae: 0.0123 - mse: 8.2024e-04 - val_loss: 0.0291 - val_mae: 0.0138 - val_mse: 8.7408e-04\n",
      "Epoch 193/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0279 - mae: 0.0121 - mse: 8.1280e-04 - val_loss: 0.0282 - val_mae: 0.0119 - val_mse: 8.2236e-04\n",
      "Epoch 194/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0275 - mae: 0.0114 - mse: 7.8418e-04 - val_loss: 0.0278 - val_mae: 0.0118 - val_mse: 8.0774e-04\n",
      "Epoch 195/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0283 - mae: 0.0125 - mse: 8.3335e-04 - val_loss: 0.0275 - val_mae: 0.0107 - val_mse: 7.8473e-04\n",
      "Epoch 196/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0279 - mae: 0.0122 - mse: 8.1467e-04 - val_loss: 0.0272 - val_mae: 0.0113 - val_mse: 7.6949e-04\n",
      "Epoch 197/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0277 - mae: 0.0118 - mse: 8.0077e-04 - val_loss: 0.0294 - val_mae: 0.0137 - val_mse: 8.9497e-04\n",
      "Epoch 198/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0282 - mae: 0.0124 - mse: 8.2629e-04 - val_loss: 0.0275 - val_mae: 0.0118 - val_mse: 7.8960e-04\n",
      "Epoch 199/500\n",
      "10200/10200 [==============================] - 0s 34us/sample - loss: 0.0284 - mae: 0.0127 - mse: 8.3705e-04 - val_loss: 0.0279 - val_mae: 0.0123 - val_mse: 8.0328e-04\n",
      "Epoch 200/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0279 - mae: 0.0121 - mse: 8.0782e-04 - val_loss: 0.0277 - val_mae: 0.0118 - val_mse: 7.8991e-04\n",
      "Epoch 201/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0276 - mae: 0.0117 - mse: 7.8873e-04 - val_loss: 0.0282 - val_mae: 0.0131 - val_mse: 8.1811e-04\n",
      "Epoch 202/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0278 - mae: 0.0122 - mse: 8.0328e-04 - val_loss: 0.0281 - val_mae: 0.0115 - val_mse: 8.1148e-04\n",
      "Epoch 203/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0275 - mae: 0.0117 - mse: 7.9039e-04 - val_loss: 0.0278 - val_mae: 0.0117 - val_mse: 7.9558e-04\n",
      "Epoch 204/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0277 - mae: 0.0117 - mse: 7.9671e-04 - val_loss: 0.0266 - val_mae: 0.0109 - val_mse: 7.3378e-04\n",
      "Epoch 205/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0277 - mae: 0.0119 - mse: 7.9715e-04 - val_loss: 0.0275 - val_mae: 0.0132 - val_mse: 7.8359e-04\n",
      "Epoch 206/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0275 - mae: 0.0117 - mse: 7.8481e-04 - val_loss: 0.0268 - val_mae: 0.0104 - val_mse: 7.4070e-04\n",
      "Epoch 207/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0276 - mae: 0.0119 - mse: 7.9199e-04 - val_loss: 0.0285 - val_mae: 0.0110 - val_mse: 8.3268e-04\n",
      "Epoch 208/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0280 - mae: 0.0122 - mse: 8.1143e-04 - val_loss: 0.0286 - val_mae: 0.0126 - val_mse: 8.4293e-04\n",
      "Epoch 209/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0279 - mae: 0.0124 - mse: 8.1499e-04 - val_loss: 0.0338 - val_mae: 0.0199 - val_mse: 0.0012\n",
      "Epoch 210/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0280 - mae: 0.0123 - mse: 8.1204e-04 - val_loss: 0.0278 - val_mae: 0.0122 - val_mse: 7.9944e-04\n",
      "Epoch 211/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0274 - mae: 0.0113 - mse: 7.7701e-04 - val_loss: 0.0287 - val_mae: 0.0131 - val_mse: 8.4558e-04\n",
      "Epoch 212/500\n",
      "10200/10200 [==============================] - 0s 42us/sample - loss: 0.0276 - mae: 0.0116 - mse: 7.8903e-04 - val_loss: 0.0269 - val_mae: 0.0108 - val_mse: 7.5154e-04\n",
      "Epoch 213/500\n",
      "10200/10200 [==============================] - 0s 45us/sample - loss: 0.0275 - mae: 0.0116 - mse: 7.8185e-04 - val_loss: 0.0270 - val_mae: 0.0116 - val_mse: 7.5230e-04\n",
      "Epoch 214/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0276 - mae: 0.0120 - mse: 7.8918e-04 - val_loss: 0.0275 - val_mae: 0.0106 - val_mse: 7.8216e-04\n",
      "Epoch 215/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0270 - mae: 0.0113 - mse: 7.6203e-04 - val_loss: 0.0276 - val_mae: 0.0129 - val_mse: 7.8451e-04\n",
      "Epoch 216/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0278 - mae: 0.0123 - mse: 8.0285e-04 - val_loss: 0.0281 - val_mae: 0.0129 - val_mse: 8.1826e-04\n",
      "Epoch 217/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0277 - mae: 0.0119 - mse: 7.9678e-04 - val_loss: 0.0263 - val_mae: 0.0105 - val_mse: 7.1329e-04\n",
      "Epoch 218/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0274 - mae: 0.0116 - mse: 7.8144e-04 - val_loss: 0.0267 - val_mae: 0.0111 - val_mse: 7.4077e-04\n",
      "Epoch 219/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0275 - mae: 0.0119 - mse: 7.8560e-04 - val_loss: 0.0277 - val_mae: 0.0128 - val_mse: 7.8859e-04\n",
      "Epoch 220/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0276 - mae: 0.0118 - mse: 7.9031e-04 - val_loss: 0.0298 - val_mae: 0.0150 - val_mse: 9.0413e-04\n",
      "Epoch 221/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0276 - mae: 0.0120 - mse: 7.9209e-04 - val_loss: 0.0271 - val_mae: 0.0102 - val_mse: 7.6243e-04\n",
      "Epoch 222/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0277 - mae: 0.0120 - mse: 8.0097e-04 - val_loss: 0.0286 - val_mae: 0.0141 - val_mse: 8.4471e-04\n",
      "Epoch 223/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0272 - mae: 0.0114 - mse: 7.6874e-04 - val_loss: 0.0262 - val_mae: 0.0105 - val_mse: 7.1445e-04\n",
      "Epoch 224/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0272 - mae: 0.0116 - mse: 7.7032e-04 - val_loss: 0.0282 - val_mae: 0.0129 - val_mse: 8.1299e-04\n",
      "Epoch 225/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0276 - mae: 0.0121 - mse: 7.8864e-04 - val_loss: 0.0265 - val_mae: 0.0108 - val_mse: 7.3344e-04\n",
      "Epoch 226/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0277 - mae: 0.0122 - mse: 7.9793e-04 - val_loss: 0.0277 - val_mae: 0.0119 - val_mse: 7.9113e-04\n",
      "Epoch 227/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0272 - mae: 0.0112 - mse: 7.6529e-04 - val_loss: 0.0275 - val_mae: 0.0119 - val_mse: 7.8191e-04\n",
      "Epoch 228/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0278 - mae: 0.0126 - mse: 8.0460e-04 - val_loss: 0.0306 - val_mae: 0.0161 - val_mse: 9.6015e-04\n",
      "Epoch 229/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0273 - mae: 0.0115 - mse: 7.7404e-04 - val_loss: 0.0274 - val_mae: 0.0121 - val_mse: 7.7060e-04\n",
      "Epoch 230/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0270 - mae: 0.0111 - mse: 7.6203e-04 - val_loss: 0.0280 - val_mae: 0.0111 - val_mse: 8.0520e-04\n",
      "Epoch 231/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0274 - mae: 0.0116 - mse: 7.7989e-04 - val_loss: 0.0276 - val_mae: 0.0124 - val_mse: 7.8759e-04\n",
      "Epoch 232/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0273 - mae: 0.0118 - mse: 7.7580e-04 - val_loss: 0.0276 - val_mae: 0.0100 - val_mse: 8.0252e-04\n",
      "Epoch 233/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0275 - mae: 0.0118 - mse: 7.8685e-04 - val_loss: 0.0266 - val_mae: 0.0097 - val_mse: 7.3156e-04\n",
      "Epoch 234/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0271 - mae: 0.0114 - mse: 7.6705e-04 - val_loss: 0.0267 - val_mae: 0.0104 - val_mse: 7.4533e-04\n",
      "Epoch 235/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0272 - mae: 0.0119 - mse: 7.7237e-04 - val_loss: 0.0267 - val_mae: 0.0115 - val_mse: 7.3910e-04\n",
      "Epoch 236/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0272 - mae: 0.0115 - mse: 7.7444e-04 - val_loss: 0.0280 - val_mae: 0.0126 - val_mse: 8.1913e-04\n",
      "Epoch 237/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0274 - mae: 0.0117 - mse: 7.7620e-04 - val_loss: 0.0282 - val_mae: 0.0122 - val_mse: 8.3192e-04\n",
      "Epoch 238/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0270 - mae: 0.0112 - mse: 7.6355e-04 - val_loss: 0.0277 - val_mae: 0.0116 - val_mse: 7.8938e-04\n",
      "Epoch 239/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0271 - mae: 0.0113 - mse: 7.6626e-04 - val_loss: 0.0290 - val_mae: 0.0126 - val_mse: 8.6158e-04\n",
      "Epoch 240/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0272 - mae: 0.0116 - mse: 7.7372e-04 - val_loss: 0.0260 - val_mae: 0.0101 - val_mse: 7.0586e-04\n",
      "Epoch 241/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0270 - mae: 0.0113 - mse: 7.6210e-04 - val_loss: 0.0259 - val_mae: 0.0095 - val_mse: 6.9730e-04\n",
      "Epoch 242/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0273 - mae: 0.0118 - mse: 7.7862e-04 - val_loss: 0.0269 - val_mae: 0.0118 - val_mse: 7.5253e-04\n",
      "Epoch 243/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0270 - mae: 0.0114 - mse: 7.6404e-04 - val_loss: 0.0270 - val_mae: 0.0116 - val_mse: 7.5404e-04\n",
      "Epoch 244/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0273 - mae: 0.0116 - mse: 7.7319e-04 - val_loss: 0.0265 - val_mae: 0.0100 - val_mse: 7.2514e-04\n",
      "Epoch 245/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0271 - mae: 0.0113 - mse: 7.6370e-04 - val_loss: 0.0276 - val_mae: 0.0112 - val_mse: 7.8120e-04\n",
      "Epoch 246/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0269 - mae: 0.0112 - mse: 7.5523e-04 - val_loss: 0.0279 - val_mae: 0.0126 - val_mse: 8.1037e-04\n",
      "Epoch 247/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0270 - mae: 0.0113 - mse: 7.5684e-04 - val_loss: 0.0264 - val_mae: 0.0110 - val_mse: 7.2642e-04\n",
      "Epoch 248/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0271 - mae: 0.0114 - mse: 7.6308e-04 - val_loss: 0.0295 - val_mae: 0.0158 - val_mse: 8.8833e-04\n",
      "Epoch 249/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0272 - mae: 0.0114 - mse: 7.6479e-04 - val_loss: 0.0268 - val_mae: 0.0122 - val_mse: 7.3895e-04\n",
      "Epoch 250/500\n",
      "10200/10200 [==============================] - 0s 42us/sample - loss: 0.0270 - mae: 0.0115 - mse: 7.5918e-04 - val_loss: 0.0265 - val_mae: 0.0112 - val_mse: 7.2501e-04\n",
      "Epoch 251/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0270 - mae: 0.0113 - mse: 7.5688e-04 - val_loss: 0.0272 - val_mae: 0.0115 - val_mse: 7.6337e-04\n",
      "Epoch 252/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0269 - mae: 0.0112 - mse: 7.5431e-04 - val_loss: 0.0292 - val_mae: 0.0145 - val_mse: 8.8085e-04\n",
      "Epoch 253/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0270 - mae: 0.0113 - mse: 7.5800e-04 - val_loss: 0.0260 - val_mae: 0.0096 - val_mse: 7.1049e-04\n",
      "Epoch 254/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0270 - mae: 0.0112 - mse: 7.5618e-04 - val_loss: 0.0284 - val_mae: 0.0125 - val_mse: 8.3831e-04\n",
      "Epoch 255/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0274 - mae: 0.0118 - mse: 7.8115e-04 - val_loss: 0.0268 - val_mae: 0.0119 - val_mse: 7.4233e-04\n",
      "Epoch 256/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0268 - mae: 0.0112 - mse: 7.4746e-04 - val_loss: 0.0270 - val_mae: 0.0113 - val_mse: 7.5474e-04\n",
      "Epoch 257/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0270 - mae: 0.0115 - mse: 7.5988e-04 - val_loss: 0.0286 - val_mae: 0.0134 - val_mse: 8.5190e-04\n",
      "Epoch 258/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0275 - mae: 0.0122 - mse: 7.9164e-04 - val_loss: 0.0276 - val_mae: 0.0110 - val_mse: 7.8374e-04\n",
      "Epoch 259/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0270 - mae: 0.0115 - mse: 7.6154e-04 - val_loss: 0.0295 - val_mae: 0.0128 - val_mse: 8.9004e-04\n",
      "Epoch 260/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0267 - mae: 0.0110 - mse: 7.4159e-04 - val_loss: 0.0273 - val_mae: 0.0119 - val_mse: 7.6742e-04\n",
      "Epoch 261/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0269 - mae: 0.0113 - mse: 7.5294e-04 - val_loss: 0.0276 - val_mae: 0.0112 - val_mse: 7.7979e-04\n",
      "Epoch 262/500\n",
      "10200/10200 [==============================] - 0s 42us/sample - loss: 0.0269 - mae: 0.0113 - mse: 7.5437e-04 - val_loss: 0.0262 - val_mae: 0.0107 - val_mse: 7.1143e-04\n",
      "Epoch 263/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0271 - mae: 0.0118 - mse: 7.6521e-04 - val_loss: 0.0266 - val_mae: 0.0106 - val_mse: 7.3123e-04\n",
      "Epoch 264/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0270 - mae: 0.0114 - mse: 7.5803e-04 - val_loss: 0.0273 - val_mae: 0.0100 - val_mse: 7.6989e-04\n",
      "Epoch 265/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0269 - mae: 0.0114 - mse: 7.5541e-04 - val_loss: 0.0276 - val_mae: 0.0124 - val_mse: 7.8668e-04\n",
      "Epoch 266/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0266 - mae: 0.0108 - mse: 7.3861e-04 - val_loss: 0.0255 - val_mae: 0.0098 - val_mse: 6.7337e-04\n",
      "Epoch 267/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0265 - mae: 0.0108 - mse: 7.3487e-04 - val_loss: 0.0261 - val_mae: 0.0104 - val_mse: 7.0457e-04\n",
      "Epoch 268/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0270 - mae: 0.0117 - mse: 7.6275e-04 - val_loss: 0.0275 - val_mae: 0.0128 - val_mse: 7.7884e-04\n",
      "Epoch 269/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0267 - mae: 0.0113 - mse: 7.4696e-04 - val_loss: 0.0270 - val_mae: 0.0113 - val_mse: 7.5433e-04\n",
      "Epoch 270/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0272 - mae: 0.0117 - mse: 7.7100e-04 - val_loss: 0.0306 - val_mae: 0.0173 - val_mse: 9.5239e-04\n",
      "Epoch 271/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0269 - mae: 0.0113 - mse: 7.5813e-04 - val_loss: 0.0264 - val_mae: 0.0109 - val_mse: 7.2259e-04\n",
      "Epoch 272/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0268 - mae: 0.0114 - mse: 7.4921e-04 - val_loss: 0.0264 - val_mae: 0.0104 - val_mse: 7.1439e-04\n",
      "Epoch 273/500\n",
      "10200/10200 [==============================] - 0s 33us/sample - loss: 0.0269 - mae: 0.0116 - mse: 7.5781e-04 - val_loss: 0.0277 - val_mae: 0.0136 - val_mse: 7.8431e-04\n",
      "Epoch 274/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0268 - mae: 0.0113 - mse: 7.4808e-04 - val_loss: 0.0270 - val_mae: 0.0116 - val_mse: 7.5091e-04\n",
      "Epoch 275/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0268 - mae: 0.0111 - mse: 7.5102e-04 - val_loss: 0.0261 - val_mae: 0.0108 - val_mse: 7.1000e-04\n",
      "Epoch 276/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0271 - mae: 0.0118 - mse: 7.6765e-04 - val_loss: 0.0264 - val_mae: 0.0109 - val_mse: 7.1927e-04\n",
      "Epoch 277/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0270 - mae: 0.0115 - mse: 7.5848e-04 - val_loss: 0.0270 - val_mae: 0.0127 - val_mse: 7.4425e-04\n",
      "Epoch 278/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0273 - mae: 0.0120 - mse: 7.7639e-04 - val_loss: 0.0269 - val_mae: 0.0112 - val_mse: 7.4072e-04\n",
      "Epoch 279/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0268 - mae: 0.0115 - mse: 7.5038e-04 - val_loss: 0.0269 - val_mae: 0.0114 - val_mse: 7.4938e-04\n",
      "Epoch 280/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0267 - mae: 0.0114 - mse: 7.4767e-04 - val_loss: 0.0262 - val_mae: 0.0116 - val_mse: 7.1132e-04\n",
      "Epoch 281/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0269 - mae: 0.0114 - mse: 7.5612e-04 - val_loss: 0.0272 - val_mae: 0.0124 - val_mse: 7.5750e-04\n",
      "Epoch 282/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0265 - mae: 0.0108 - mse: 7.3012e-04 - val_loss: 0.0274 - val_mae: 0.0118 - val_mse: 7.7359e-04\n",
      "Epoch 283/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0266 - mae: 0.0110 - mse: 7.4109e-04 - val_loss: 0.0282 - val_mae: 0.0144 - val_mse: 8.1599e-04\n",
      "Epoch 284/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0268 - mae: 0.0113 - mse: 7.4608e-04 - val_loss: 0.0257 - val_mae: 0.0107 - val_mse: 6.8730e-04\n",
      "Epoch 285/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0268 - mae: 0.0114 - mse: 7.4533e-04 - val_loss: 0.0262 - val_mae: 0.0110 - val_mse: 7.0934e-04\n",
      "Epoch 286/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0268 - mae: 0.0112 - mse: 7.4348e-04 - val_loss: 0.0277 - val_mae: 0.0111 - val_mse: 7.8701e-04\n",
      "Epoch 287/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0267 - mae: 0.0112 - mse: 7.4460e-04 - val_loss: 0.0264 - val_mae: 0.0118 - val_mse: 7.2376e-04\n",
      "Epoch 288/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0269 - mae: 0.0113 - mse: 7.5253e-04 - val_loss: 0.0262 - val_mae: 0.0104 - val_mse: 7.0734e-04\n",
      "Epoch 289/500\n",
      "10200/10200 [==============================] - 0s 42us/sample - loss: 0.0272 - mae: 0.0118 - mse: 7.6876e-04 - val_loss: 0.0263 - val_mae: 0.0109 - val_mse: 7.1416e-04\n",
      "Epoch 290/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0271 - mae: 0.0117 - mse: 7.6440e-04 - val_loss: 0.0258 - val_mae: 0.0101 - val_mse: 6.9290e-04\n",
      "Epoch 291/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0264 - mae: 0.0106 - mse: 7.2506e-04 - val_loss: 0.0260 - val_mae: 0.0109 - val_mse: 7.0388e-04\n",
      "Epoch 292/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0265 - mae: 0.0109 - mse: 7.3149e-04 - val_loss: 0.0263 - val_mae: 0.0119 - val_mse: 7.1383e-04\n",
      "Epoch 293/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0269 - mae: 0.0114 - mse: 7.5557e-04 - val_loss: 0.0261 - val_mae: 0.0104 - val_mse: 7.0409e-04\n",
      "Epoch 294/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0267 - mae: 0.0110 - mse: 7.4080e-04 - val_loss: 0.0258 - val_mae: 0.0102 - val_mse: 6.9428e-04\n",
      "Epoch 295/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0266 - mae: 0.0110 - mse: 7.4003e-04 - val_loss: 0.0270 - val_mae: 0.0109 - val_mse: 7.4828e-04\n",
      "Epoch 296/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0268 - mae: 0.0115 - mse: 7.4803e-04 - val_loss: 0.0287 - val_mae: 0.0157 - val_mse: 8.5028e-04\n",
      "Epoch 297/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0265 - mae: 0.0110 - mse: 7.3281e-04 - val_loss: 0.0254 - val_mae: 0.0094 - val_mse: 6.7544e-04\n",
      "Epoch 298/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0265 - mae: 0.0110 - mse: 7.3811e-04 - val_loss: 0.0282 - val_mae: 0.0139 - val_mse: 8.1566e-04\n",
      "Epoch 299/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0267 - mae: 0.0112 - mse: 7.3860e-04 - val_loss: 0.0263 - val_mae: 0.0101 - val_mse: 7.1370e-04\n",
      "Epoch 300/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0267 - mae: 0.0113 - mse: 7.4046e-04 - val_loss: 0.0259 - val_mae: 0.0104 - val_mse: 6.9531e-04\n",
      "Epoch 301/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0269 - mae: 0.0117 - mse: 7.5595e-04 - val_loss: 0.0259 - val_mae: 0.0098 - val_mse: 7.0017e-04\n",
      "Epoch 302/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0266 - mae: 0.0110 - mse: 7.3784e-04 - val_loss: 0.0276 - val_mae: 0.0121 - val_mse: 7.8808e-04\n",
      "Epoch 303/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0269 - mae: 0.0118 - mse: 7.5617e-04 - val_loss: 0.0258 - val_mae: 0.0101 - val_mse: 6.8997e-04\n",
      "Epoch 304/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0266 - mae: 0.0112 - mse: 7.4171e-04 - val_loss: 0.0251 - val_mae: 0.0097 - val_mse: 6.5573e-04\n",
      "Epoch 305/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0268 - mae: 0.0113 - mse: 7.4854e-04 - val_loss: 0.0270 - val_mae: 0.0126 - val_mse: 7.4759e-04\n",
      "Epoch 306/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0264 - mae: 0.0105 - mse: 7.2150e-04 - val_loss: 0.0265 - val_mae: 0.0116 - val_mse: 7.2874e-04\n",
      "Epoch 307/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0265 - mae: 0.0111 - mse: 7.3290e-04 - val_loss: 0.0262 - val_mae: 0.0105 - val_mse: 7.1416e-04\n",
      "Epoch 308/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0266 - mae: 0.0111 - mse: 7.4210e-04 - val_loss: 0.0260 - val_mae: 0.0109 - val_mse: 6.9754e-04\n",
      "Epoch 309/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0266 - mae: 0.0112 - mse: 7.4239e-04 - val_loss: 0.0258 - val_mae: 0.0108 - val_mse: 6.9162e-04\n",
      "Epoch 310/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0268 - mae: 0.0116 - mse: 7.4885e-04 - val_loss: 0.0259 - val_mae: 0.0108 - val_mse: 6.9605e-04\n",
      "Epoch 311/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0264 - mae: 0.0108 - mse: 7.2956e-04 - val_loss: 0.0272 - val_mae: 0.0119 - val_mse: 7.7038e-04\n",
      "Epoch 312/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0265 - mae: 0.0111 - mse: 7.3267e-04 - val_loss: 0.0270 - val_mae: 0.0116 - val_mse: 7.5731e-04\n",
      "Epoch 313/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0266 - mae: 0.0113 - mse: 7.3770e-04 - val_loss: 0.0260 - val_mae: 0.0109 - val_mse: 6.9947e-04\n",
      "Epoch 314/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0265 - mae: 0.0110 - mse: 7.3352e-04 - val_loss: 0.0261 - val_mae: 0.0111 - val_mse: 7.0195e-04\n",
      "Epoch 315/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0265 - mae: 0.0112 - mse: 7.3735e-04 - val_loss: 0.0266 - val_mae: 0.0117 - val_mse: 7.2638e-04\n",
      "Epoch 316/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0264 - mae: 0.0111 - mse: 7.2802e-04 - val_loss: 0.0257 - val_mae: 0.0107 - val_mse: 6.8581e-04\n",
      "Epoch 317/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0264 - mae: 0.0110 - mse: 7.2897e-04 - val_loss: 0.0251 - val_mae: 0.0095 - val_mse: 6.5617e-04\n",
      "Epoch 318/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0264 - mae: 0.0108 - mse: 7.3022e-04 - val_loss: 0.0270 - val_mae: 0.0111 - val_mse: 7.5296e-04\n",
      "Epoch 319/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0267 - mae: 0.0112 - mse: 7.4437e-04 - val_loss: 0.0256 - val_mae: 0.0098 - val_mse: 6.8159e-04\n",
      "Epoch 320/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0264 - mae: 0.0108 - mse: 7.2455e-04 - val_loss: 0.0267 - val_mae: 0.0124 - val_mse: 7.3944e-04\n",
      "Epoch 321/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0265 - mae: 0.0109 - mse: 7.3315e-04 - val_loss: 0.0251 - val_mae: 0.0092 - val_mse: 6.5667e-04\n",
      "Epoch 322/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0265 - mae: 0.0113 - mse: 7.3615e-04 - val_loss: 0.0280 - val_mae: 0.0152 - val_mse: 8.0386e-04\n",
      "Epoch 323/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0263 - mae: 0.0108 - mse: 7.1875e-04 - val_loss: 0.0256 - val_mae: 0.0097 - val_mse: 6.7872e-04\n",
      "Epoch 324/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0265 - mae: 0.0111 - mse: 7.3478e-04 - val_loss: 0.0261 - val_mae: 0.0113 - val_mse: 7.0369e-04\n",
      "Epoch 325/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0262 - mae: 0.0106 - mse: 7.1549e-04 - val_loss: 0.0255 - val_mae: 0.0092 - val_mse: 6.7435e-04\n",
      "Epoch 326/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0267 - mae: 0.0116 - mse: 7.4580e-04 - val_loss: 0.0321 - val_mae: 0.0208 - val_mse: 0.0010\n",
      "Epoch 327/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0264 - mae: 0.0107 - mse: 7.2752e-04 - val_loss: 0.0271 - val_mae: 0.0123 - val_mse: 7.5655e-04\n",
      "Epoch 328/500\n",
      "10200/10200 [==============================] - 0s 45us/sample - loss: 0.0264 - mae: 0.0112 - mse: 7.3282e-04 - val_loss: 0.0250 - val_mae: 0.0095 - val_mse: 6.4973e-04\n",
      "Epoch 329/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0266 - mae: 0.0114 - mse: 7.4279e-04 - val_loss: 0.0262 - val_mae: 0.0106 - val_mse: 7.0331e-04\n",
      "Epoch 330/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0261 - mae: 0.0106 - mse: 7.1117e-04 - val_loss: 0.0269 - val_mae: 0.0106 - val_mse: 7.4548e-04\n",
      "Epoch 331/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0263 - mae: 0.0109 - mse: 7.2372e-04 - val_loss: 0.0251 - val_mae: 0.0096 - val_mse: 6.5586e-04\n",
      "Epoch 332/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0260 - mae: 0.0104 - mse: 7.0773e-04 - val_loss: 0.0252 - val_mae: 0.0100 - val_mse: 6.6275e-04\n",
      "Epoch 333/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0264 - mae: 0.0109 - mse: 7.2617e-04 - val_loss: 0.0269 - val_mae: 0.0115 - val_mse: 7.5236e-04\n",
      "Epoch 334/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0270 - mae: 0.0120 - mse: 7.5832e-04 - val_loss: 0.0271 - val_mae: 0.0131 - val_mse: 7.5235e-04\n",
      "Epoch 335/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0265 - mae: 0.0112 - mse: 7.3075e-04 - val_loss: 0.0255 - val_mae: 0.0097 - val_mse: 6.8163e-04\n",
      "Epoch 336/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0262 - mae: 0.0106 - mse: 7.1709e-04 - val_loss: 0.0262 - val_mae: 0.0104 - val_mse: 7.1040e-04\n",
      "Epoch 337/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0266 - mae: 0.0113 - mse: 7.3461e-04 - val_loss: 0.0267 - val_mae: 0.0121 - val_mse: 7.4059e-04\n",
      "Epoch 338/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0264 - mae: 0.0112 - mse: 7.3009e-04 - val_loss: 0.0262 - val_mae: 0.0102 - val_mse: 7.0569e-04\n",
      "Epoch 339/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0262 - mae: 0.0105 - mse: 7.1457e-04 - val_loss: 0.0260 - val_mae: 0.0106 - val_mse: 6.9847e-04\n",
      "Epoch 340/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0261 - mae: 0.0106 - mse: 7.0920e-04 - val_loss: 0.0265 - val_mae: 0.0118 - val_mse: 7.2603e-04\n",
      "Epoch 341/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0265 - mae: 0.0109 - mse: 7.2735e-04 - val_loss: 0.0277 - val_mae: 0.0128 - val_mse: 7.9853e-04\n",
      "Epoch 342/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0265 - mae: 0.0113 - mse: 7.3217e-04 - val_loss: 0.0253 - val_mae: 0.0103 - val_mse: 6.6743e-04\n",
      "Epoch 343/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0261 - mae: 0.0106 - mse: 7.0905e-04 - val_loss: 0.0252 - val_mae: 0.0094 - val_mse: 6.6496e-04\n",
      "Epoch 344/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0260 - mae: 0.0104 - mse: 7.0461e-04 - val_loss: 0.0279 - val_mae: 0.0132 - val_mse: 7.9414e-04\n",
      "Epoch 345/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0263 - mae: 0.0111 - mse: 7.2507e-04 - val_loss: 0.0255 - val_mae: 0.0102 - val_mse: 6.7170e-04\n",
      "Epoch 346/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0263 - mae: 0.0110 - mse: 7.2595e-04 - val_loss: 0.0269 - val_mae: 0.0125 - val_mse: 7.4538e-04\n",
      "Epoch 347/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0262 - mae: 0.0109 - mse: 7.2033e-04 - val_loss: 0.0256 - val_mae: 0.0103 - val_mse: 6.8287e-04\n",
      "Epoch 348/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0262 - mae: 0.0107 - mse: 7.1462e-04 - val_loss: 0.0258 - val_mae: 0.0110 - val_mse: 6.9149e-04\n",
      "Epoch 349/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0261 - mae: 0.0107 - mse: 7.1402e-04 - val_loss: 0.0264 - val_mae: 0.0110 - val_mse: 7.2471e-04\n",
      "Epoch 350/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0260 - mae: 0.0104 - mse: 7.0556e-04 - val_loss: 0.0251 - val_mae: 0.0098 - val_mse: 6.5409e-04\n",
      "Epoch 351/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0265 - mae: 0.0112 - mse: 7.2899e-04 - val_loss: 0.0255 - val_mae: 0.0104 - val_mse: 6.7137e-04\n",
      "Epoch 352/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0266 - mae: 0.0115 - mse: 7.4199e-04 - val_loss: 0.0262 - val_mae: 0.0119 - val_mse: 7.1589e-04\n",
      "Epoch 353/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0263 - mae: 0.0107 - mse: 7.2193e-04 - val_loss: 0.0265 - val_mae: 0.0118 - val_mse: 7.2680e-04\n",
      "Epoch 354/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0262 - mae: 0.0109 - mse: 7.1906e-04 - val_loss: 0.0263 - val_mae: 0.0120 - val_mse: 7.1446e-04\n",
      "Epoch 355/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0263 - mae: 0.0112 - mse: 7.2507e-04 - val_loss: 0.0261 - val_mae: 0.0116 - val_mse: 7.0232e-04\n",
      "Epoch 356/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0263 - mae: 0.0111 - mse: 7.2198e-04 - val_loss: 0.0254 - val_mae: 0.0100 - val_mse: 6.7205e-04\n",
      "Epoch 357/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0264 - mae: 0.0109 - mse: 7.2700e-04 - val_loss: 0.0261 - val_mae: 0.0108 - val_mse: 6.9864e-04\n",
      "Epoch 358/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0260 - mae: 0.0102 - mse: 7.0726e-04 - val_loss: 0.0263 - val_mae: 0.0106 - val_mse: 7.2297e-04\n",
      "Epoch 359/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0260 - mae: 0.0103 - mse: 7.0616e-04 - val_loss: 0.0259 - val_mae: 0.0111 - val_mse: 6.9656e-04\n",
      "Epoch 360/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0261 - mae: 0.0108 - mse: 7.1197e-04 - val_loss: 0.0273 - val_mae: 0.0103 - val_mse: 7.6811e-04\n",
      "Epoch 361/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0263 - mae: 0.0109 - mse: 7.2201e-04 - val_loss: 0.0261 - val_mae: 0.0100 - val_mse: 7.0549e-04\n",
      "Epoch 362/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0262 - mae: 0.0109 - mse: 7.1661e-04 - val_loss: 0.0261 - val_mae: 0.0112 - val_mse: 7.0529e-04\n",
      "Epoch 363/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0260 - mae: 0.0106 - mse: 7.0847e-04 - val_loss: 0.0259 - val_mae: 0.0106 - val_mse: 6.9602e-04\n",
      "Epoch 364/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0261 - mae: 0.0106 - mse: 7.1219e-04 - val_loss: 0.0260 - val_mae: 0.0104 - val_mse: 7.0350e-04\n",
      "Epoch 365/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0265 - mae: 0.0112 - mse: 7.3068e-04 - val_loss: 0.0256 - val_mae: 0.0100 - val_mse: 6.8124e-04\n",
      "Epoch 366/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0262 - mae: 0.0111 - mse: 7.2077e-04 - val_loss: 0.0254 - val_mae: 0.0095 - val_mse: 6.6433e-04\n",
      "Epoch 367/500\n",
      "10200/10200 [==============================] - 0s 42us/sample - loss: 0.0263 - mae: 0.0111 - mse: 7.2241e-04 - val_loss: 0.0264 - val_mae: 0.0111 - val_mse: 7.1787e-04\n",
      "Epoch 368/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0265 - mae: 0.0111 - mse: 7.2731e-04 - val_loss: 0.0256 - val_mae: 0.0103 - val_mse: 6.7817e-04\n",
      "Epoch 369/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0261 - mae: 0.0107 - mse: 7.1675e-04 - val_loss: 0.0265 - val_mae: 0.0113 - val_mse: 7.2222e-04\n",
      "Epoch 370/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0261 - mae: 0.0108 - mse: 7.1350e-04 - val_loss: 0.0251 - val_mae: 0.0101 - val_mse: 6.5003e-04\n",
      "Epoch 371/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0260 - mae: 0.0104 - mse: 7.0412e-04 - val_loss: 0.0259 - val_mae: 0.0099 - val_mse: 6.9322e-04\n",
      "Epoch 372/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0264 - mae: 0.0112 - mse: 7.2500e-04 - val_loss: 0.0252 - val_mae: 0.0097 - val_mse: 6.5998e-04\n",
      "Epoch 373/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0259 - mae: 0.0102 - mse: 7.0009e-04 - val_loss: 0.0274 - val_mae: 0.0115 - val_mse: 7.8186e-04\n",
      "Epoch 374/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0266 - mae: 0.0114 - mse: 7.3664e-04 - val_loss: 0.0276 - val_mae: 0.0143 - val_mse: 7.8112e-04\n",
      "Epoch 375/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0264 - mae: 0.0113 - mse: 7.2685e-04 - val_loss: 0.0247 - val_mae: 0.0087 - val_mse: 6.4412e-04\n",
      "Epoch 376/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0260 - mae: 0.0105 - mse: 7.0624e-04 - val_loss: 0.0265 - val_mae: 0.0119 - val_mse: 7.2482e-04\n",
      "Epoch 377/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0256 - mae: 0.0100 - mse: 6.8885e-04 - val_loss: 0.0270 - val_mae: 0.0115 - val_mse: 7.5169e-04\n",
      "Epoch 378/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0264 - mae: 0.0112 - mse: 7.2993e-04 - val_loss: 0.0255 - val_mae: 0.0105 - val_mse: 6.7825e-04\n",
      "Epoch 379/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0264 - mae: 0.0113 - mse: 7.2334e-04 - val_loss: 0.0261 - val_mae: 0.0113 - val_mse: 6.9916e-04\n",
      "Epoch 380/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0264 - mae: 0.0115 - mse: 7.2632e-04 - val_loss: 0.0264 - val_mae: 0.0125 - val_mse: 7.1961e-04\n",
      "Epoch 381/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0261 - mae: 0.0111 - mse: 7.1442e-04 - val_loss: 0.0255 - val_mae: 0.0107 - val_mse: 6.7156e-04\n",
      "Epoch 382/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0264 - mae: 0.0112 - mse: 7.2511e-04 - val_loss: 0.0259 - val_mae: 0.0112 - val_mse: 6.9438e-04\n",
      "Epoch 383/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0259 - mae: 0.0104 - mse: 7.0041e-04 - val_loss: 0.0263 - val_mae: 0.0108 - val_mse: 7.1011e-04\n",
      "Epoch 384/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0259 - mae: 0.0104 - mse: 7.0256e-04 - val_loss: 0.0259 - val_mae: 0.0091 - val_mse: 6.9325e-04\n",
      "Epoch 385/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0259 - mae: 0.0103 - mse: 7.0017e-04 - val_loss: 0.0249 - val_mae: 0.0091 - val_mse: 6.4445e-04\n",
      "Epoch 386/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0262 - mae: 0.0110 - mse: 7.1665e-04 - val_loss: 0.0262 - val_mae: 0.0107 - val_mse: 7.0830e-04\n",
      "Epoch 387/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0264 - mae: 0.0111 - mse: 7.2576e-04 - val_loss: 0.0263 - val_mae: 0.0115 - val_mse: 7.1451e-04\n",
      "Epoch 388/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0257 - mae: 0.0101 - mse: 6.9363e-04 - val_loss: 0.0285 - val_mae: 0.0132 - val_mse: 8.4609e-04\n",
      "Epoch 389/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0262 - mae: 0.0111 - mse: 7.1680e-04 - val_loss: 0.0255 - val_mae: 0.0107 - val_mse: 6.7366e-04\n",
      "Epoch 390/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0264 - mae: 0.0113 - mse: 7.2663e-04 - val_loss: 0.0267 - val_mae: 0.0117 - val_mse: 7.3748e-04\n",
      "Epoch 391/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0260 - mae: 0.0105 - mse: 7.0472e-04 - val_loss: 0.0269 - val_mae: 0.0127 - val_mse: 7.4773e-04\n",
      "Epoch 392/500\n",
      "10200/10200 [==============================] - 0s 41us/sample - loss: 0.0260 - mae: 0.0106 - mse: 7.0254e-04 - val_loss: 0.0264 - val_mae: 0.0114 - val_mse: 7.1798e-04\n",
      "Epoch 393/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0262 - mae: 0.0109 - mse: 7.1627e-04 - val_loss: 0.0267 - val_mae: 0.0107 - val_mse: 7.3537e-04\n",
      "Epoch 394/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0259 - mae: 0.0105 - mse: 6.9995e-04 - val_loss: 0.0250 - val_mae: 0.0095 - val_mse: 6.4884e-04\n",
      "Epoch 395/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0256 - mae: 0.0099 - mse: 6.8334e-04 - val_loss: 0.0289 - val_mae: 0.0137 - val_mse: 8.6972e-04\n",
      "Epoch 396/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0263 - mae: 0.0112 - mse: 7.2337e-04 - val_loss: 0.0253 - val_mae: 0.0098 - val_mse: 6.6511e-04\n",
      "Epoch 397/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0258 - mae: 0.0105 - mse: 6.9682e-04 - val_loss: 0.0261 - val_mae: 0.0122 - val_mse: 7.0490e-04\n",
      "Epoch 398/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0257 - mae: 0.0104 - mse: 6.9428e-04 - val_loss: 0.0255 - val_mae: 0.0112 - val_mse: 6.7365e-04\n",
      "Epoch 399/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0260 - mae: 0.0106 - mse: 7.0388e-04 - val_loss: 0.0261 - val_mae: 0.0117 - val_mse: 7.0478e-04\n",
      "Epoch 400/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0261 - mae: 0.0106 - mse: 7.0934e-04 - val_loss: 0.0255 - val_mae: 0.0103 - val_mse: 6.7431e-04\n",
      "Epoch 401/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0259 - mae: 0.0104 - mse: 7.0012e-04 - val_loss: 0.0246 - val_mae: 0.0089 - val_mse: 6.3469e-04\n",
      "Epoch 402/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0258 - mae: 0.0106 - mse: 7.0087e-04 - val_loss: 0.0253 - val_mae: 0.0104 - val_mse: 6.6607e-04\n",
      "Epoch 403/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0259 - mae: 0.0106 - mse: 7.0547e-04 - val_loss: 0.0258 - val_mae: 0.0098 - val_mse: 6.8280e-04\n",
      "Epoch 404/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0260 - mae: 0.0107 - mse: 7.0691e-04 - val_loss: 0.0273 - val_mae: 0.0123 - val_mse: 7.6482e-04\n",
      "Epoch 405/500\n",
      "10200/10200 [==============================] - 0s 42us/sample - loss: 0.0260 - mae: 0.0106 - mse: 7.0421e-04 - val_loss: 0.0265 - val_mae: 0.0108 - val_mse: 7.2407e-04\n",
      "Epoch 406/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0267 - mae: 0.0117 - mse: 7.4194e-04 - val_loss: 0.0261 - val_mae: 0.0129 - val_mse: 7.0078e-04\n",
      "Epoch 407/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0265 - mae: 0.0115 - mse: 7.3657e-04 - val_loss: 0.0247 - val_mae: 0.0097 - val_mse: 6.3664e-04\n",
      "Epoch 408/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0253 - mae: 0.0097 - mse: 6.6831e-04 - val_loss: 0.0258 - val_mae: 0.0100 - val_mse: 6.8504e-04\n",
      "Epoch 409/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0258 - mae: 0.0105 - mse: 6.9637e-04 - val_loss: 0.0254 - val_mae: 0.0100 - val_mse: 6.6273e-04\n",
      "Epoch 410/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0260 - mae: 0.0107 - mse: 7.0538e-04 - val_loss: 0.0244 - val_mae: 0.0088 - val_mse: 6.2505e-04\n",
      "Epoch 411/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0260 - mae: 0.0106 - mse: 7.0795e-04 - val_loss: 0.0270 - val_mae: 0.0109 - val_mse: 7.4661e-04\n",
      "Epoch 412/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0259 - mae: 0.0107 - mse: 7.0451e-04 - val_loss: 0.0247 - val_mae: 0.0090 - val_mse: 6.2957e-04\n",
      "Epoch 413/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0255 - mae: 0.0099 - mse: 6.7784e-04 - val_loss: 0.0253 - val_mae: 0.0101 - val_mse: 6.6359e-04\n",
      "Epoch 414/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0257 - mae: 0.0102 - mse: 6.8857e-04 - val_loss: 0.0253 - val_mae: 0.0110 - val_mse: 6.6156e-04\n",
      "Epoch 415/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0260 - mae: 0.0109 - mse: 7.0786e-04 - val_loss: 0.0262 - val_mae: 0.0121 - val_mse: 7.0491e-04\n",
      "Epoch 416/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0257 - mae: 0.0104 - mse: 6.9067e-04 - val_loss: 0.0260 - val_mae: 0.0123 - val_mse: 6.9812e-04\n",
      "Epoch 417/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0257 - mae: 0.0103 - mse: 6.8931e-04 - val_loss: 0.0259 - val_mae: 0.0105 - val_mse: 6.9248e-04\n",
      "Epoch 418/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0259 - mae: 0.0106 - mse: 7.0187e-04 - val_loss: 0.0248 - val_mae: 0.0095 - val_mse: 6.4416e-04\n",
      "Epoch 419/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0259 - mae: 0.0105 - mse: 6.9698e-04 - val_loss: 0.0263 - val_mae: 0.0122 - val_mse: 7.1074e-04\n",
      "Epoch 420/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0261 - mae: 0.0111 - mse: 7.1494e-04 - val_loss: 0.0256 - val_mae: 0.0104 - val_mse: 6.7548e-04\n",
      "Epoch 421/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0258 - mae: 0.0103 - mse: 6.9487e-04 - val_loss: 0.0253 - val_mae: 0.0102 - val_mse: 6.6435e-04\n",
      "Epoch 422/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0260 - mae: 0.0108 - mse: 7.0463e-04 - val_loss: 0.0266 - val_mae: 0.0118 - val_mse: 7.3857e-04\n",
      "Epoch 423/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0259 - mae: 0.0107 - mse: 6.9766e-04 - val_loss: 0.0260 - val_mae: 0.0112 - val_mse: 7.0309e-04\n",
      "Epoch 424/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0258 - mae: 0.0105 - mse: 6.9875e-04 - val_loss: 0.0257 - val_mae: 0.0107 - val_mse: 6.8543e-04\n",
      "Epoch 425/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0264 - mae: 0.0113 - mse: 7.2502e-04 - val_loss: 0.0257 - val_mae: 0.0103 - val_mse: 6.8562e-04\n",
      "Epoch 426/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0257 - mae: 0.0102 - mse: 6.8899e-04 - val_loss: 0.0252 - val_mae: 0.0090 - val_mse: 6.5225e-04\n",
      "Epoch 427/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0260 - mae: 0.0108 - mse: 7.0730e-04 - val_loss: 0.0264 - val_mae: 0.0117 - val_mse: 7.1883e-04\n",
      "Epoch 428/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0257 - mae: 0.0105 - mse: 6.9172e-04 - val_loss: 0.0258 - val_mae: 0.0115 - val_mse: 6.8640e-04\n",
      "Epoch 429/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0262 - mae: 0.0113 - mse: 7.1891e-04 - val_loss: 0.0254 - val_mae: 0.0103 - val_mse: 6.6602e-04\n",
      "Epoch 430/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0255 - mae: 0.0101 - mse: 6.8312e-04 - val_loss: 0.0252 - val_mae: 0.0102 - val_mse: 6.5645e-04\n",
      "Epoch 431/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0256 - mae: 0.0103 - mse: 6.8897e-04 - val_loss: 0.0257 - val_mae: 0.0096 - val_mse: 6.8592e-04\n",
      "Epoch 432/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0261 - mae: 0.0111 - mse: 7.1123e-04 - val_loss: 0.0259 - val_mae: 0.0112 - val_mse: 6.8956e-04\n",
      "Epoch 433/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0261 - mae: 0.0107 - mse: 7.0711e-04 - val_loss: 0.0282 - val_mae: 0.0143 - val_mse: 8.1095e-04\n",
      "Epoch 434/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0261 - mae: 0.0111 - mse: 7.1115e-04 - val_loss: 0.0261 - val_mae: 0.0118 - val_mse: 7.0810e-04\n",
      "Epoch 435/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0256 - mae: 0.0100 - mse: 6.8516e-04 - val_loss: 0.0263 - val_mae: 0.0115 - val_mse: 7.1274e-04\n",
      "Epoch 436/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0257 - mae: 0.0102 - mse: 6.9060e-04 - val_loss: 0.0259 - val_mae: 0.0121 - val_mse: 6.9209e-04\n",
      "Epoch 437/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0259 - mae: 0.0105 - mse: 6.9648e-04 - val_loss: 0.0250 - val_mae: 0.0096 - val_mse: 6.5173e-04\n",
      "Epoch 438/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0256 - mae: 0.0105 - mse: 6.8616e-04 - val_loss: 0.0280 - val_mae: 0.0137 - val_mse: 8.0322e-04\n",
      "Epoch 439/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0261 - mae: 0.0112 - mse: 7.1239e-04 - val_loss: 0.0265 - val_mae: 0.0101 - val_mse: 7.2259e-04\n",
      "Epoch 440/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0259 - mae: 0.0107 - mse: 7.0173e-04 - val_loss: 0.0251 - val_mae: 0.0094 - val_mse: 6.5129e-04\n",
      "Epoch 441/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0257 - mae: 0.0104 - mse: 6.8927e-04 - val_loss: 0.0255 - val_mae: 0.0104 - val_mse: 6.7731e-04\n",
      "Epoch 442/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0255 - mae: 0.0102 - mse: 6.8016e-04 - val_loss: 0.0263 - val_mae: 0.0108 - val_mse: 7.0900e-04\n",
      "Epoch 443/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0257 - mae: 0.0103 - mse: 6.9108e-04 - val_loss: 0.0251 - val_mae: 0.0100 - val_mse: 6.5450e-04\n",
      "Epoch 444/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0257 - mae: 0.0105 - mse: 6.9038e-04 - val_loss: 0.0255 - val_mae: 0.0099 - val_mse: 6.7181e-04\n",
      "Epoch 445/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0256 - mae: 0.0104 - mse: 6.8836e-04 - val_loss: 0.0274 - val_mae: 0.0127 - val_mse: 7.7688e-04\n",
      "Epoch 446/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0260 - mae: 0.0109 - mse: 7.0396e-04 - val_loss: 0.0245 - val_mae: 0.0094 - val_mse: 6.2120e-04\n",
      "Epoch 447/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0255 - mae: 0.0099 - mse: 6.7831e-04 - val_loss: 0.0258 - val_mae: 0.0107 - val_mse: 6.8931e-04\n",
      "Epoch 448/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0255 - mae: 0.0101 - mse: 6.7820e-04 - val_loss: 0.0256 - val_mae: 0.0116 - val_mse: 6.7894e-04\n",
      "Epoch 449/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0258 - mae: 0.0107 - mse: 7.0003e-04 - val_loss: 0.0264 - val_mae: 0.0117 - val_mse: 7.1757e-04\n",
      "Epoch 450/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0259 - mae: 0.0106 - mse: 6.9906e-04 - val_loss: 0.0247 - val_mae: 0.0096 - val_mse: 6.3599e-04\n",
      "Epoch 451/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0255 - mae: 0.0102 - mse: 6.8229e-04 - val_loss: 0.0272 - val_mae: 0.0121 - val_mse: 7.6600e-04\n",
      "Epoch 452/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0259 - mae: 0.0110 - mse: 7.0459e-04 - val_loss: 0.0249 - val_mae: 0.0094 - val_mse: 6.4365e-04\n",
      "Epoch 453/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0257 - mae: 0.0104 - mse: 6.9037e-04 - val_loss: 0.0252 - val_mae: 0.0096 - val_mse: 6.5638e-04\n",
      "Epoch 454/500\n",
      "10200/10200 [==============================] - 0s 39us/sample - loss: 0.0261 - mae: 0.0111 - mse: 7.0959e-04 - val_loss: 0.0260 - val_mae: 0.0105 - val_mse: 7.0260e-04\n",
      "Epoch 455/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0256 - mae: 0.0103 - mse: 6.8502e-04 - val_loss: 0.0268 - val_mae: 0.0109 - val_mse: 7.4038e-04\n",
      "Epoch 456/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0256 - mae: 0.0102 - mse: 6.8561e-04 - val_loss: 0.0269 - val_mae: 0.0107 - val_mse: 7.4834e-04\n",
      "Epoch 457/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0257 - mae: 0.0102 - mse: 6.9360e-04 - val_loss: 0.0254 - val_mae: 0.0091 - val_mse: 6.6253e-04\n",
      "Epoch 458/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0260 - mae: 0.0110 - mse: 7.0677e-04 - val_loss: 0.0258 - val_mae: 0.0107 - val_mse: 6.9454e-04\n",
      "Epoch 459/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0257 - mae: 0.0104 - mse: 6.9163e-04 - val_loss: 0.0248 - val_mae: 0.0085 - val_mse: 6.4321e-04\n",
      "Epoch 460/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0255 - mae: 0.0103 - mse: 6.8222e-04 - val_loss: 0.0251 - val_mae: 0.0094 - val_mse: 6.6251e-04\n",
      "Epoch 461/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0258 - mae: 0.0105 - mse: 6.9509e-04 - val_loss: 0.0248 - val_mae: 0.0088 - val_mse: 6.3378e-04\n",
      "Epoch 462/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0257 - mae: 0.0104 - mse: 6.9109e-04 - val_loss: 0.0271 - val_mae: 0.0128 - val_mse: 7.6333e-04\n",
      "Epoch 463/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0259 - mae: 0.0109 - mse: 7.0101e-04 - val_loss: 0.0251 - val_mae: 0.0096 - val_mse: 6.5326e-04\n",
      "Epoch 464/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0255 - mae: 0.0101 - mse: 6.8116e-04 - val_loss: 0.0251 - val_mae: 0.0097 - val_mse: 6.5392e-04\n",
      "Epoch 465/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0255 - mae: 0.0100 - mse: 6.8135e-04 - val_loss: 0.0277 - val_mae: 0.0138 - val_mse: 7.9545e-04\n",
      "Epoch 466/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0257 - mae: 0.0104 - mse: 6.9377e-04 - val_loss: 0.0263 - val_mae: 0.0111 - val_mse: 7.0933e-04\n",
      "Epoch 467/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0257 - mae: 0.0107 - mse: 6.9252e-04 - val_loss: 0.0252 - val_mae: 0.0102 - val_mse: 6.5626e-04\n",
      "Epoch 468/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0256 - mae: 0.0101 - mse: 6.8482e-04 - val_loss: 0.0265 - val_mae: 0.0123 - val_mse: 7.1879e-04\n",
      "Epoch 469/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0254 - mae: 0.0101 - mse: 6.7466e-04 - val_loss: 0.0249 - val_mae: 0.0091 - val_mse: 6.4471e-04\n",
      "Epoch 470/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0257 - mae: 0.0104 - mse: 6.9373e-04 - val_loss: 0.0251 - val_mae: 0.0108 - val_mse: 6.5491e-04\n",
      "Epoch 471/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0256 - mae: 0.0104 - mse: 6.8383e-04 - val_loss: 0.0243 - val_mae: 0.0094 - val_mse: 6.1536e-04\n",
      "Epoch 472/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0253 - mae: 0.0099 - mse: 6.7614e-04 - val_loss: 0.0268 - val_mae: 0.0134 - val_mse: 7.3778e-04\n",
      "Epoch 473/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0255 - mae: 0.0105 - mse: 6.8401e-04 - val_loss: 0.0243 - val_mae: 0.0090 - val_mse: 6.1550e-04\n",
      "Epoch 474/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0258 - mae: 0.0104 - mse: 6.8988e-04 - val_loss: 0.0270 - val_mae: 0.0126 - val_mse: 7.4751e-04\n",
      "Epoch 475/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0254 - mae: 0.0099 - mse: 6.7570e-04 - val_loss: 0.0255 - val_mae: 0.0104 - val_mse: 6.7457e-04\n",
      "Epoch 476/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0258 - mae: 0.0105 - mse: 6.9410e-04 - val_loss: 0.0263 - val_mae: 0.0101 - val_mse: 7.1008e-04\n",
      "Epoch 477/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0257 - mae: 0.0105 - mse: 6.8945e-04 - val_loss: 0.0254 - val_mae: 0.0102 - val_mse: 6.6671e-04\n",
      "Epoch 478/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0257 - mae: 0.0102 - mse: 6.8979e-04 - val_loss: 0.0254 - val_mae: 0.0113 - val_mse: 6.7143e-04\n",
      "Epoch 479/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0259 - mae: 0.0108 - mse: 7.0027e-04 - val_loss: 0.0251 - val_mae: 0.0087 - val_mse: 6.4930e-04\n",
      "Epoch 480/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0259 - mae: 0.0109 - mse: 7.0042e-04 - val_loss: 0.0262 - val_mae: 0.0121 - val_mse: 7.0839e-04\n",
      "Epoch 481/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0261 - mae: 0.0111 - mse: 7.0846e-04 - val_loss: 0.0271 - val_mae: 0.0127 - val_mse: 7.5445e-04\n",
      "Epoch 482/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0256 - mae: 0.0100 - mse: 6.8334e-04 - val_loss: 0.0262 - val_mae: 0.0116 - val_mse: 7.0658e-04\n",
      "Epoch 483/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0255 - mae: 0.0100 - mse: 6.7630e-04 - val_loss: 0.0258 - val_mae: 0.0105 - val_mse: 6.8737e-04\n",
      "Epoch 484/500\n",
      "10200/10200 [==============================] - 0s 38us/sample - loss: 0.0257 - mae: 0.0105 - mse: 6.8907e-04 - val_loss: 0.0262 - val_mae: 0.0115 - val_mse: 7.0636e-04\n",
      "Epoch 485/500\n",
      "10200/10200 [==============================] - 0s 40us/sample - loss: 0.0257 - mae: 0.0104 - mse: 6.8968e-04 - val_loss: 0.0278 - val_mae: 0.0134 - val_mse: 8.0063e-04\n",
      "Epoch 486/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0257 - mae: 0.0104 - mse: 6.8812e-04 - val_loss: 0.0248 - val_mae: 0.0103 - val_mse: 6.3883e-04\n",
      "Epoch 487/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0254 - mae: 0.0100 - mse: 6.7198e-04 - val_loss: 0.0244 - val_mae: 0.0087 - val_mse: 6.2207e-04\n",
      "Epoch 488/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0258 - mae: 0.0109 - mse: 6.9532e-04 - val_loss: 0.0245 - val_mae: 0.0090 - val_mse: 6.2435e-04\n",
      "Epoch 489/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0256 - mae: 0.0102 - mse: 6.8189e-04 - val_loss: 0.0258 - val_mae: 0.0108 - val_mse: 6.8928e-04\n",
      "Epoch 490/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0258 - mae: 0.0108 - mse: 6.9512e-04 - val_loss: 0.0247 - val_mae: 0.0096 - val_mse: 6.3261e-04\n",
      "Epoch 491/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0254 - mae: 0.0102 - mse: 6.8003e-04 - val_loss: 0.0256 - val_mae: 0.0103 - val_mse: 6.8182e-04\n",
      "Epoch 492/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0254 - mae: 0.0101 - mse: 6.7409e-04 - val_loss: 0.0261 - val_mae: 0.0109 - val_mse: 7.0223e-04\n",
      "Epoch 493/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0259 - mae: 0.0109 - mse: 6.9870e-04 - val_loss: 0.0260 - val_mae: 0.0116 - val_mse: 6.9789e-04\n",
      "Epoch 494/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0255 - mae: 0.0102 - mse: 6.7741e-04 - val_loss: 0.0254 - val_mae: 0.0095 - val_mse: 6.6893e-04\n",
      "Epoch 495/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0253 - mae: 0.0099 - mse: 6.6973e-04 - val_loss: 0.0250 - val_mae: 0.0094 - val_mse: 6.4733e-04\n",
      "Epoch 496/500\n",
      "10200/10200 [==============================] - 0s 37us/sample - loss: 0.0254 - mae: 0.0102 - mse: 6.8400e-04 - val_loss: 0.0253 - val_mae: 0.0105 - val_mse: 6.6237e-04\n",
      "Epoch 497/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0258 - mae: 0.0106 - mse: 6.9485e-04 - val_loss: 0.0254 - val_mae: 0.0100 - val_mse: 6.7387e-04\n",
      "Epoch 498/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0255 - mae: 0.0102 - mse: 6.7956e-04 - val_loss: 0.0253 - val_mae: 0.0108 - val_mse: 6.6684e-04\n",
      "Epoch 499/500\n",
      "10200/10200 [==============================] - 0s 36us/sample - loss: 0.0254 - mae: 0.0100 - mse: 6.7580e-04 - val_loss: 0.0248 - val_mae: 0.0097 - val_mse: 6.3751e-04\n",
      "Epoch 500/500\n",
      "10200/10200 [==============================] - 0s 35us/sample - loss: 0.0255 - mae: 0.0101 - mse: 6.7731e-04 - val_loss: 0.0258 - val_mae: 0.0120 - val_mse: 6.8548e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_transform, y_train_transform, validation_data = (x_test_transform, y_test_transform), epochs = 500, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "qx-slEWsRih_",
    "outputId": "0a73e312-d114-4667-9665-50705e6e0ef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 - 0s - loss: 0.0258 - mae: 0.0120 - mse: 6.8548e-04\n",
      "Testing set Mean Abs Error:  0.01 MPG\n"
     ]
    }
   ],
   "source": [
    "loss, mae, mse = model.evaluate(x_test_transform, y_test_transform, verbose=2)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n",
    "\n",
    "plotter.plot({'History': history}, metric = \"mse\")\n",
    "plt.ylim([0,0.001])\n",
    "plt.ylabel('MSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "h22odDX7wfFk",
    "outputId": "c0792810-e0a4-4a49-c08f-d07958d98a9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30678253, -0.32841243,  0.5897173 , -1.91192873,  0.81697685]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_transform[1250].reshape(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SV1f7VDhvtIA"
   },
   "outputs": [],
   "source": [
    "pred = xinversetransform(model.predict(x_test_transform[1250].reshape(1,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "m53RDpT24kLE",
    "outputId": "0a4c0905-8f00-4459-b0f2-37ad18b09150"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3108948 , 0.24637875, 0.21793331, 0.1898825 , 0.16647723,\n",
       "        0.17469415, 0.21351048, 0.24737085, 0.27492288, 0.29802594,\n",
       "        0.3176645 , 0.24662517, 0.22317125, 0.20439719, 0.19181935,\n",
       "        0.19078265, 0.20432831, 0.22479367, 0.245385  , 0.2640831 ,\n",
       "        0.28072482, 0.2955678 , 0.2213285 , 0.20992324, 0.2038548 ,\n",
       "        0.2041381 , 0.21051158, 0.22081147, 0.23274387, 0.24482785,\n",
       "        0.25637105, 0.2671513 , 0.27713782, 0.21325609, 0.20899251,\n",
       "        0.20916401, 0.21314003, 0.21968728, 0.22760923, 0.23602127,\n",
       "        0.24439982, 0.25247166, 0.26011774, 0.26731512, 0.21184431,\n",
       "        0.2116151 , 0.21432981, 0.21904342, 0.22489528, 0.23126252,\n",
       "        0.2377391 , 0.24408951, 0.2501977 , 0.25601226, 0.2615118 ,\n",
       "        0.2129694 , 0.21478336, 0.21838531, 0.22302651, 0.22817783,\n",
       "        0.2334893 , 0.23876095, 0.24387264, 0.24877007, 0.25343126,\n",
       "        0.25785062, 0.21493566, 0.21772346, 0.22155498, 0.22590788,\n",
       "        0.23045315, 0.23500402, 0.2394399 , 0.24370475, 0.24777928,\n",
       "        0.251652  , 0.25532097, 0.21633586, 0.21944204, 0.22326477,\n",
       "        0.22739974, 0.23161323, 0.23576249, 0.23977424, 0.24361764,\n",
       "        0.24727553, 0.2507498 , 0.25404653]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "0cJVkzgXk9B_",
    "outputId": "861adf0c-4407-4774-8314-6c37bbe46913"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WnpCvrmtv0c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DNN_2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
